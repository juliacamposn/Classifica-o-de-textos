{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliacamposn/Classifica-o-de-textos/blob/main/trabalho_2_classifca%C3%A7%C3%A3o_de_texto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo roberta-base-go_emotions\n",
        "# Classificação de emoções"
      ],
      "metadata": {
        "id": "AhT2M7mOKG8Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMaL6LguREFG",
        "outputId": "a2ca06cc-1073-4df9-dab7-d809e5496742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer #\n",
        "from transformers import BertForPreTraining\n",
        "from transformers import BertModel\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ux_-nxwvTc6o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "UFmqCNeu8yB1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#modelo bert-base-multilingual-cased\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "#model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")"
      ],
      "metadata": {
        "id": "O5sM1-q-XEVb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modelo 2 talvez: analise de sentimentos -> bertweet-base-sentiment-analysis\n",
        "# ou roberta-base-go_emotions\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
        "model = AutoModel.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")"
      ],
      "metadata": {
        "id": "qvfH1iD6ZyuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "637888da-45be-4a1c-b80a-51c2b85e37a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NpxtJXObIv7",
        "outputId": "17978bcb-e421-4579-eda4-c7621641ec6e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaModel(\n",
              "  (embeddings): RobertaEmbeddings(\n",
              "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "    (token_type_embeddings): Embedding(1, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): RobertaEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSdpaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): RobertaPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "zXqTLLGy5Ek7"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")"
      ],
      "metadata": {
        "id": "0ic2Cs_N5U5a"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o modelo base\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\",num_labels=3)"
      ],
      "metadata": {
        "id": "r9Hx359IS9PR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "id": "KWuDig4G5jMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "425c6fe7-35f5-405c-fd19-0d245ad8d742"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"A cor do céu é bonita\"\n",
        "token = tokenizer(texto, return_tensors='pt')\n",
        "\n",
        "# Movendo os tensores para a GPU\n",
        "input_ids = token['input_ids'].to(device)\n",
        "attention_mask = token['attention_mask'].to(device)\n",
        "\n",
        "# Inferência\n",
        "out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "# Verificando a saída\n",
        "print(out)\n"
      ],
      "metadata": {
        "id": "GSfOSZwiEfsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f61b412-2a99-453b-9f61-3cec357eded8"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SequenceClassifierOutput(loss=None, logits=tensor([[ 2.5443, -2.8951,  0.6688]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=(tensor([[[ 0.1367, -0.0655, -0.0026,  ..., -0.0469,  0.0793,  0.0470],\n",
            "         [ 0.0746, -0.1163,  0.1331,  ..., -0.0527, -0.2640,  0.5015],\n",
            "         [ 0.0111,  0.3632,  0.0670,  ...,  0.0217, -0.1677,  0.2245],\n",
            "         ...,\n",
            "         [ 0.3650, -0.2828,  0.4530,  ...,  0.6998,  0.3236, -0.5199],\n",
            "         [ 0.1933,  0.3888, -0.0970,  ..., -0.4813, -0.0297,  0.0225],\n",
            "         [-0.0237, -0.0015,  0.1094,  ...,  0.3862,  0.0482,  0.0028]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0060,  0.0291, -0.0076,  ..., -0.0478,  0.0252,  0.0121],\n",
            "         [ 0.0962, -0.6000,  0.2478,  ..., -0.3371, -0.1319,  0.7620],\n",
            "         [ 0.2574,  0.5681, -0.3116,  ..., -0.2652, -0.1143,  0.3815],\n",
            "         ...,\n",
            "         [-0.0109, -0.4678,  0.2323,  ...,  1.2689,  1.0102, -0.7833],\n",
            "         [ 0.3095,  0.4618,  0.5474,  ..., -1.5782, -0.2799, -0.5663],\n",
            "         [-0.0673,  0.3277, -0.0505,  ...,  0.3329, -0.1627, -0.5518]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0139,  0.0429,  0.0268,  ..., -0.0808,  0.0510,  0.0200],\n",
            "         [-0.1934, -0.3295,  0.3422,  ..., -0.3777,  0.3847,  0.8414],\n",
            "         [ 0.0152,  1.0735, -0.7565,  ..., -0.2891,  0.3495,  0.4658],\n",
            "         ...,\n",
            "         [ 0.2291, -0.0877,  0.1283,  ...,  1.3765,  1.1898, -0.6176],\n",
            "         [ 0.5890,  0.5424,  0.0586,  ..., -1.8761, -0.1999, -0.6023],\n",
            "         [-0.4899,  0.2650,  0.3937,  ...,  0.5603, -0.2355, -0.4952]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.1392,  0.1245,  0.1013,  ...,  0.0711, -0.0532,  0.1219],\n",
            "         [-0.2543,  0.0287, -0.6357,  ..., -0.2860,  0.1723,  0.5875],\n",
            "         [ 0.4079,  1.2870, -0.2002,  ..., -0.2537, -0.3012,  0.2559],\n",
            "         ...,\n",
            "         [-0.1642,  0.0016,  0.6383,  ...,  1.2587,  0.4983, -0.1359],\n",
            "         [ 0.2129,  0.4781, -0.3672,  ..., -1.5918, -0.7300, -0.0842],\n",
            "         [-0.2053,  0.2758,  0.2825,  ...,  0.2128,  0.2508, -0.0051]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-5.1514e-02,  2.0591e-01,  1.2420e-01,  ...,  3.0239e-02,\n",
            "           2.8508e-02,  2.7530e-02],\n",
            "         [-3.2568e-01,  5.5232e-01,  5.3051e-01,  ...,  1.8645e-02,\n",
            "           1.8763e-03,  2.3677e-01],\n",
            "         [ 1.4128e-01,  1.9361e+00,  1.1777e+00,  ...,  7.2390e-01,\n",
            "          -2.4774e-01, -2.0954e-01],\n",
            "         ...,\n",
            "         [-9.3716e-02,  3.5913e-01,  1.1977e+00,  ...,  1.8307e+00,\n",
            "           4.4520e-01, -2.6601e-01],\n",
            "         [-3.5923e-01,  1.0135e+00,  8.0084e-01,  ..., -5.5994e-01,\n",
            "           1.6101e-02, -2.2562e-01],\n",
            "         [ 8.8363e-02,  3.6347e-02,  5.7996e-02,  ...,  5.3354e-02,\n",
            "           8.3412e-02,  1.7725e-02]]], device='cuda:0',\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.1258,  0.0929,  0.0755,  ...,  0.1499, -0.0301, -0.0436],\n",
            "         [-0.1354,  0.5571,  0.2388,  ..., -0.0025, -0.0396,  0.0499],\n",
            "         [ 0.0131,  1.3277,  0.5752,  ...,  0.8507, -0.1624, -0.3929],\n",
            "         ...,\n",
            "         [-0.0967,  0.1220,  0.4777,  ...,  1.0408,  0.1882, -0.2332],\n",
            "         [ 0.0968,  0.8668,  0.3241,  ..., -0.3285,  0.2153, -0.1043],\n",
            "         [ 0.0626,  0.0338,  0.0135,  ...,  0.0774, -0.0053, -0.0160]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0632,  0.1647,  0.0235,  ...,  0.1610, -0.1977,  0.1655],\n",
            "         [-0.3331,  0.0783, -0.4145,  ...,  0.0354,  0.3550,  0.0287],\n",
            "         [-0.2623,  0.8319,  0.4396,  ...,  0.3565,  0.2424, -0.2535],\n",
            "         ...,\n",
            "         [-0.1518, -0.0466,  0.0348,  ...,  0.4751,  0.3622, -0.3237],\n",
            "         [-0.3767,  0.3090, -0.2275,  ..., -0.2464,  0.3383, -0.3672],\n",
            "         [ 0.0677, -0.0164,  0.0040,  ...,  0.0151, -0.0801,  0.0086]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0056,  0.1361, -0.0832,  ...,  0.2132, -0.0746,  0.1817],\n",
            "         [-0.1641, -0.2004, -0.3821,  ..., -0.2519,  0.4620, -0.2528],\n",
            "         [-0.1571,  0.7958,  0.6015,  ...,  0.2522,  0.4264, -0.3842],\n",
            "         ...,\n",
            "         [-0.0628,  0.0779,  0.4361,  ...,  0.1831,  0.3551, -0.5821],\n",
            "         [-0.1846,  0.2620,  0.1219,  ..., -0.5478,  0.5711, -0.6124],\n",
            "         [ 0.0927,  0.0751, -0.0461,  ..., -0.0706, -0.0269,  0.0444]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0954,  0.0235, -0.0392,  ...,  0.0713, -0.0252,  0.0470],\n",
            "         [-0.3024, -0.4856, -0.5446,  ...,  0.2279,  0.0081,  0.0493],\n",
            "         [-0.0810,  0.6474, -0.2669,  ...,  0.7158,  0.0872, -0.1310],\n",
            "         ...,\n",
            "         [ 0.2241,  0.0226, -0.1172,  ...,  0.4174, -0.1937, -0.2969],\n",
            "         [ 0.0235, -0.0281, -0.0833,  ..., -0.2707,  0.0478, -0.3114],\n",
            "         [ 0.0678,  0.1103,  0.0236,  ...,  0.0678, -0.0218, -0.0459]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 1.2453e-01,  8.5291e-02, -2.1389e-02,  ...,  7.9179e-02,\n",
            "          -4.3604e-03, -8.6874e-02],\n",
            "         [ 6.3968e-01,  7.9240e-02, -8.0414e-02,  ...,  4.3766e-01,\n",
            "           3.9195e-01, -8.2300e-01],\n",
            "         [ 3.1920e-01,  9.1778e-01,  1.9510e-02,  ...,  9.0755e-01,\n",
            "           3.6588e-01, -7.7370e-01],\n",
            "         ...,\n",
            "         [ 5.8882e-01,  4.7938e-01,  9.1880e-02,  ...,  5.7021e-01,\n",
            "           2.2460e-01, -1.0488e+00],\n",
            "         [ 7.1291e-01,  5.0041e-01,  3.7174e-02,  ...,  7.9198e-02,\n",
            "           4.2012e-01, -8.7616e-01],\n",
            "         [ 1.0499e-01,  1.2591e-01,  1.6772e-04,  ...,  7.6943e-02,\n",
            "          -3.0422e-03, -7.6570e-02]]], device='cuda:0',\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.1027,  0.0328, -0.0858,  ...,  0.1314,  0.2159, -0.0910],\n",
            "         [ 0.7638,  0.5365,  0.0315,  ...,  0.5443,  0.6881, -0.4660],\n",
            "         [ 0.6494,  0.6510, -0.1044,  ...,  0.9526,  0.4539, -0.6937],\n",
            "         ...,\n",
            "         [ 0.6816,  0.3289, -0.0039,  ...,  0.6726,  0.2373, -0.8617],\n",
            "         [ 0.7513,  0.5113, -0.1550,  ...,  0.4450,  0.7168, -0.8212],\n",
            "         [-0.1118,  0.0559, -0.0911,  ...,  0.1232,  0.2237, -0.0893]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.2888,  0.2152, -0.1244,  ...,  0.7677,  0.0164, -0.0325],\n",
            "         [ 0.4368,  0.6841,  0.1563,  ...,  0.8516,  0.4465, -0.0175],\n",
            "         [-0.1636,  0.9166, -0.2446,  ...,  0.8426,  0.2633, -0.1086],\n",
            "         ...,\n",
            "         [-0.2128,  0.6606, -0.0074,  ...,  0.7547,  0.1949, -0.2670],\n",
            "         [-0.2006,  0.8923, -0.1558,  ...,  0.5388,  0.3952, -0.2169],\n",
            "         [ 0.2829,  0.2289, -0.1212,  ...,  0.7636,  0.0178, -0.0327]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.1662,  1.2084,  0.3107,  ...,  0.7519, -0.2609, -0.1534],\n",
            "         [ 0.0249,  1.4536,  0.4501,  ...,  1.0004, -0.1348, -0.3284],\n",
            "         [-0.0355,  1.4591,  0.4089,  ...,  1.0395, -0.3022, -0.2732],\n",
            "         ...,\n",
            "         [-0.0553,  1.4166,  0.5019,  ...,  1.1713, -0.2834, -0.3288],\n",
            "         [-0.0299,  1.5054,  0.4645,  ...,  1.0201, -0.1940, -0.3995],\n",
            "         [-0.1684,  1.2103,  0.3113,  ...,  0.7534, -0.2614, -0.1582]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)), attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out[0].shape"
      ],
      "metadata": {
        "id": "-Rpzo4Bj2VAs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85e59843-f8db-4cad-dff0-a6d46dcd8e0e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out[0][0,0]"
      ],
      "metadata": {
        "id": "jOPel10JE2j0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb6908d2-f01b-4ae0-f0cb-ae79e43718ff"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.6215, device='cuda:0', grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#verificação da ultima camada\n",
        "last_layer= out[0][:,:]\n",
        "last_layer.shape"
      ],
      "metadata": {
        "id": "xz7D5q2PE9_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f317873c-8fd8-48a0-e9c6-e87032bc5df7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(last_layer,dim=1)"
      ],
      "metadata": {
        "id": "2yEv2XjRFOyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95af028c-f9ec-4d91-ac6e-07ee7c4559a2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0092], device='cuda:0', grad_fn=<MeanBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out[0][0].shape"
      ],
      "metadata": {
        "id": "MD8lsRohFZ_m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94c18171-9673-4069-b7de-dcb848b90b4b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config"
      ],
      "metadata": {
        "id": "O8SFx9kZFhpb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05b65ed5-bae4-49e2-de7e-a784d584a862"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaConfig {\n",
              "  \"_attn_implementation_autoset\": true,\n",
              "  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-sentiment\",\n",
              "  \"architectures\": [\n",
              "    \"RobertaForSequenceClassification\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"bos_token_id\": 0,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"id2label\": {\n",
              "    \"0\": \"LABEL_0\",\n",
              "    \"1\": \"LABEL_1\",\n",
              "    \"2\": \"LABEL_2\"\n",
              "  },\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"label2id\": {\n",
              "    \"LABEL_0\": 0,\n",
              "    \"LABEL_1\": 1,\n",
              "    \"LABEL_2\": 2\n",
              "  },\n",
              "  \"layer_norm_eps\": 1e-05,\n",
              "  \"max_position_embeddings\": 514,\n",
              "  \"model_type\": \"roberta\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 1,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.46.2\",\n",
              "  \"type_vocab_size\": 1,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 50265\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertPreTrainedModel\n",
        "from typing import List, Optional, Tuple, Union"
      ],
      "metadata": {
        "id": "i7hGpv-mOSlK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adicionando camdas personalizadas ao modelo\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self,model,num_labels):\n",
        "        super(Classifier,self).__init__()\n",
        "        self.bert = model\n",
        "        self.config = model.config\n",
        "        self.num_labels = num_labels\n",
        "        self.cls = nn.Linear(self.config.hidden_size,400)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.cls2 = nn.Linear(400,num_labels)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.join_strategy = 'zero'\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        ) ->Tuple[torch.Tensor]:\n",
        "\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "        if self.join_strategy == 'zero':\n",
        "            sequence_output = outputs[0][:,0,:]\n",
        "        else:\n",
        "            last_layer= outputs[0][:,:,:]\n",
        "            sequence_output = torch.mean(last_layer,dim=1)\n",
        "        prediction = self.cls(sequence_output)\n",
        "        prediction = self.gelu(prediction)\n",
        "        prediction = self.dropout(prediction)\n",
        "        prediction = self.cls2(prediction)\n",
        "        return prediction"
      ],
      "metadata": {
        "id": "4_Gz4IFENWZ4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Classifier(model=model, num_labels=3)"
      ],
      "metadata": {
        "id": "iClnND-nNjwB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "smFnwS3KOnlP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "000f446b-29ff-4c10-f45a-3cc2f713e8e0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier(\n",
              "  (bert): RobertaForSequenceClassification(\n",
              "    (roberta): RobertaModel(\n",
              "      (embeddings): RobertaEmbeddings(\n",
              "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "        (token_type_embeddings): Embedding(1, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): RobertaEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0-11): 12 x RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSdpaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (classifier): RobertaClassificationHead(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (cls): Linear(in_features=768, out_features=400, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (cls2): Linear(in_features=400, out_features=3, bias=True)\n",
              "  (gelu): GELU(approximate='none')\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construção do dataset\n"
      ],
      "metadata": {
        "id": "xSkC8F_GKiVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0Z_eWjKRK9pT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "628e9b5b-b57b-4767-a696-8988bd3d398f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "2KaACbjyomkd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/t2-ia')"
      ],
      "metadata": {
        "id": "eVZSt_ufosQY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "ybb_ABs9oxrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d255ecda-2222-47c5-cdf3-ff516d533b4c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'emocoes1.0 - emocoes(2).csv'   emocoes2.0.csv\t emocoes3.0.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('emocoes3.0.csv')"
      ],
      "metadata": {
        "id": "eXrz7oZEo21i"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "j3WcnR99u0gp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "03fc158a-1869-468a-fd72-2fac68949095"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 text  label\n",
              "0             Esse produto é péssimo.      0\n",
              "1          Não gostei do atendimento.      0\n",
              "2               A comida estava fria.      0\n",
              "3           O serviço foi muito ruim.      0\n",
              "4         Nada funciona direito aqui.      0\n",
              "5                  O preço é absurdo.      0\n",
              "6  Foi uma experiência decepcionante.      0\n",
              "7     Não voltarei mais a este lugar.      0\n",
              "8           A entrega atrasou demais.      0\n",
              "9           Estou muito insatisfeito.      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ca9657a-70a7-4535-b300-5dba0486ad7c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Esse produto é péssimo.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Não gostei do atendimento.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A comida estava fria.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>O serviço foi muito ruim.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nada funciona direito aqui.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>O preço é absurdo.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Foi uma experiência decepcionante.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Não voltarei mais a este lugar.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>A entrega atrasou demais.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Estou muito insatisfeito.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ca9657a-70a7-4535-b300-5dba0486ad7c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4ca9657a-70a7-4535-b300-5dba0486ad7c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4ca9657a-70a7-4535-b300-5dba0486ad7c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ae77c8a0-8985-4386-9204-602273b620dd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ae77c8a0-8985-4386-9204-602273b620dd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ae77c8a0-8985-4386-9204-602273b620dd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 302,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 302,\n        \"samples\": [\n          \"O rel\\u00f3gio foi ajustado para o hor\\u00e1rio de ver\\u00e3o.\",\n          \"A equipe foi super prestativa.\",\n          \"A encomenda chegou na portaria.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "YVip2txrjKMV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "35d157c3-aca1-476d-e312-2d073e9376de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of                                                   text  label\n",
              "0                              Esse produto é péssimo.      0\n",
              "1                           Não gostei do atendimento.      0\n",
              "2                                A comida estava fria.      0\n",
              "3                            O serviço foi muito ruim.      0\n",
              "4                          Nada funciona direito aqui.      0\n",
              "..                                                 ...    ...\n",
              "297         A decoração do lugar é de muito bom gosto.      2\n",
              "298  O processo foi muito mais simples do que eu im...      2\n",
              "299        Estou extremamente feliz com minha escolha.      2\n",
              "300                    A experiência foi inesquecível.      2\n",
              "301          Fui surpreendido de forma muito positiva!      2\n",
              "\n",
              "[302 rows x 2 columns]>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.generic.NDFrame.describe</b><br/>def describe(percentiles=None, include=None, exclude=None) -&gt; Self</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py</a>Generate descriptive statistics.\n",
              "\n",
              "Descriptive statistics include those that summarize the central\n",
              "tendency, dispersion and shape of a\n",
              "dataset&#x27;s distribution, excluding ``NaN`` values.\n",
              "\n",
              "Analyzes both numeric and object series, as well\n",
              "as ``DataFrame`` column sets of mixed data types. The output\n",
              "will vary depending on what is provided. Refer to the notes\n",
              "below for more detail.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "percentiles : list-like of numbers, optional\n",
              "    The percentiles to include in the output. All should\n",
              "    fall between 0 and 1. The default is\n",
              "    ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
              "    75th percentiles.\n",
              "include : &#x27;all&#x27;, list-like of dtypes or None (default), optional\n",
              "    A white list of data types to include in the result. Ignored\n",
              "    for ``Series``. Here are the options:\n",
              "\n",
              "    - &#x27;all&#x27; : All columns of the input will be included in the output.\n",
              "    - A list-like of dtypes : Limits the results to the\n",
              "      provided data types.\n",
              "      To limit the result to numeric types submit\n",
              "      ``numpy.number``. To limit it instead to object columns submit\n",
              "      the ``numpy.object`` data type. Strings\n",
              "      can also be used in the style of\n",
              "      ``select_dtypes`` (e.g. ``df.describe(include=[&#x27;O&#x27;])``). To\n",
              "      select pandas categorical columns, use ``&#x27;category&#x27;``\n",
              "    - None (default) : The result will include all numeric columns.\n",
              "exclude : list-like of dtypes or None (default), optional,\n",
              "    A black list of data types to omit from the result. Ignored\n",
              "    for ``Series``. Here are the options:\n",
              "\n",
              "    - A list-like of dtypes : Excludes the provided data types\n",
              "      from the result. To exclude numeric types submit\n",
              "      ``numpy.number``. To exclude object columns submit the data\n",
              "      type ``numpy.object``. Strings can also be used in the style of\n",
              "      ``select_dtypes`` (e.g. ``df.describe(exclude=[&#x27;O&#x27;])``). To\n",
              "      exclude pandas categorical columns, use ``&#x27;category&#x27;``\n",
              "    - None (default) : The result will exclude nothing.\n",
              "\n",
              "Returns\n",
              "-------\n",
              "Series or DataFrame\n",
              "    Summary statistics of the Series or Dataframe provided.\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.count: Count number of non-NA/null observations.\n",
              "DataFrame.max: Maximum of the values in the object.\n",
              "DataFrame.min: Minimum of the values in the object.\n",
              "DataFrame.mean: Mean of the values.\n",
              "DataFrame.std: Standard deviation of the observations.\n",
              "DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
              "    columns based on their dtype.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "For numeric data, the result&#x27;s index will include ``count``,\n",
              "``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
              "upper percentiles. By default the lower percentile is ``25`` and the\n",
              "upper percentile is ``75``. The ``50`` percentile is the\n",
              "same as the median.\n",
              "\n",
              "For object data (e.g. strings or timestamps), the result&#x27;s index\n",
              "will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
              "is the most common value. The ``freq`` is the most common value&#x27;s\n",
              "frequency. Timestamps also include the ``first`` and ``last`` items.\n",
              "\n",
              "If multiple object values have the highest count, then the\n",
              "``count`` and ``top`` results will be arbitrarily chosen from\n",
              "among those with the highest count.\n",
              "\n",
              "For mixed data types provided via a ``DataFrame``, the default is to\n",
              "return only an analysis of numeric columns. If the dataframe consists\n",
              "only of object and categorical data without any numeric columns, the\n",
              "default is to return an analysis of both the object and categorical\n",
              "columns. If ``include=&#x27;all&#x27;`` is provided as an option, the result\n",
              "will include a union of attributes of each type.\n",
              "\n",
              "The `include` and `exclude` parameters can be used to limit\n",
              "which columns in a ``DataFrame`` are analyzed for the output.\n",
              "The parameters are ignored when analyzing a ``Series``.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Describing a numeric ``Series``.\n",
              "\n",
              "&gt;&gt;&gt; s = pd.Series([1, 2, 3])\n",
              "&gt;&gt;&gt; s.describe()\n",
              "count    3.0\n",
              "mean     2.0\n",
              "std      1.0\n",
              "min      1.0\n",
              "25%      1.5\n",
              "50%      2.0\n",
              "75%      2.5\n",
              "max      3.0\n",
              "dtype: float64\n",
              "\n",
              "Describing a categorical ``Series``.\n",
              "\n",
              "&gt;&gt;&gt; s = pd.Series([&#x27;a&#x27;, &#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; s.describe()\n",
              "count     4\n",
              "unique    3\n",
              "top       a\n",
              "freq      2\n",
              "dtype: object\n",
              "\n",
              "Describing a timestamp ``Series``.\n",
              "\n",
              "&gt;&gt;&gt; s = pd.Series([\n",
              "...     np.datetime64(&quot;2000-01-01&quot;),\n",
              "...     np.datetime64(&quot;2010-01-01&quot;),\n",
              "...     np.datetime64(&quot;2010-01-01&quot;)\n",
              "... ])\n",
              "&gt;&gt;&gt; s.describe()\n",
              "count                      3\n",
              "mean     2006-09-01 08:00:00\n",
              "min      2000-01-01 00:00:00\n",
              "25%      2004-12-31 12:00:00\n",
              "50%      2010-01-01 00:00:00\n",
              "75%      2010-01-01 00:00:00\n",
              "max      2010-01-01 00:00:00\n",
              "dtype: object\n",
              "\n",
              "Describing a ``DataFrame``. By default only numeric fields\n",
              "are returned.\n",
              "\n",
              "&gt;&gt;&gt; df = pd.DataFrame({&#x27;categorical&#x27;: pd.Categorical([&#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;]),\n",
              "...                    &#x27;numeric&#x27;: [1, 2, 3],\n",
              "...                    &#x27;object&#x27;: [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]\n",
              "...                    })\n",
              "&gt;&gt;&gt; df.describe()\n",
              "       numeric\n",
              "count      3.0\n",
              "mean       2.0\n",
              "std        1.0\n",
              "min        1.0\n",
              "25%        1.5\n",
              "50%        2.0\n",
              "75%        2.5\n",
              "max        3.0\n",
              "\n",
              "Describing all columns of a ``DataFrame`` regardless of data type.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(include=&#x27;all&#x27;)  # doctest: +SKIP\n",
              "       categorical  numeric object\n",
              "count            3      3.0      3\n",
              "unique           3      NaN      3\n",
              "top              f      NaN      a\n",
              "freq             1      NaN      1\n",
              "mean           NaN      2.0    NaN\n",
              "std            NaN      1.0    NaN\n",
              "min            NaN      1.0    NaN\n",
              "25%            NaN      1.5    NaN\n",
              "50%            NaN      2.0    NaN\n",
              "75%            NaN      2.5    NaN\n",
              "max            NaN      3.0    NaN\n",
              "\n",
              "Describing a column from a ``DataFrame`` by accessing it as\n",
              "an attribute.\n",
              "\n",
              "&gt;&gt;&gt; df.numeric.describe()\n",
              "count    3.0\n",
              "mean     2.0\n",
              "std      1.0\n",
              "min      1.0\n",
              "25%      1.5\n",
              "50%      2.0\n",
              "75%      2.5\n",
              "max      3.0\n",
              "Name: numeric, dtype: float64\n",
              "\n",
              "Including only numeric columns in a ``DataFrame`` description.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(include=[np.number])\n",
              "       numeric\n",
              "count      3.0\n",
              "mean       2.0\n",
              "std        1.0\n",
              "min        1.0\n",
              "25%        1.5\n",
              "50%        2.0\n",
              "75%        2.5\n",
              "max        3.0\n",
              "\n",
              "Including only string columns in a ``DataFrame`` description.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(include=[object])  # doctest: +SKIP\n",
              "       object\n",
              "count       3\n",
              "unique      3\n",
              "top         a\n",
              "freq        1\n",
              "\n",
              "Including only categorical columns from a ``DataFrame`` description.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(include=[&#x27;category&#x27;])\n",
              "       categorical\n",
              "count            3\n",
              "unique           3\n",
              "top              d\n",
              "freq             1\n",
              "\n",
              "Excluding numeric columns from a ``DataFrame`` description.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(exclude=[np.number])  # doctest: +SKIP\n",
              "       categorical object\n",
              "count            3      3\n",
              "unique           3      3\n",
              "top              f      a\n",
              "freq             1      1\n",
              "\n",
              "Excluding object columns from a ``DataFrame`` description.\n",
              "\n",
              "&gt;&gt;&gt; df.describe(exclude=[object])  # doctest: +SKIP\n",
              "       categorical  numeric\n",
              "count            3      3.0\n",
              "unique           3      NaN\n",
              "top              f      NaN\n",
              "freq             1      NaN\n",
              "mean           NaN      2.0\n",
              "std            NaN      1.0\n",
              "min            NaN      1.0\n",
              "25%            NaN      1.5\n",
              "50%            NaN      2.0\n",
              "75%            NaN      2.5\n",
              "max            NaN      3.0</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 11734);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "data.describe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "ke0fkEmtjR2r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "43db9137-9635-4416-d4f4-9f715c153eaf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "1    101\n",
              "2    101\n",
              "0    100\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "data['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1ELSgwdejZWD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "f4ccc87e-8faf-4682-c24c-eb4bbcbc13ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                Esse produto é péssimo.\n",
              "1                             Não gostei do atendimento.\n",
              "2                                  A comida estava fria.\n",
              "3                              O serviço foi muito ruim.\n",
              "4                            Nada funciona direito aqui.\n",
              "                             ...                        \n",
              "297           A decoração do lugar é de muito bom gosto.\n",
              "298    O processo foi muito mais simples do que eu im...\n",
              "299          Estou extremamente feliz com minha escolha.\n",
              "300                      A experiência foi inesquecível.\n",
              "301            Fui surpreendido de forma muito positiva!\n",
              "Name: text, Length: 302, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Esse produto é péssimo.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Não gostei do atendimento.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A comida estava fria.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>O serviço foi muito ruim.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nada funciona direito aqui.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>A decoração do lugar é de muito bom gosto.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>O processo foi muito mais simples do que eu im...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>Estou extremamente feliz com minha escolha.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>A experiência foi inesquecível.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>Fui surpreendido de forma muito positiva!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>302 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "data['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "R5Z5ts1gni4V"
      },
      "outputs": [],
      "source": [
        "shuffle=np.random.randint(0,len(data['text']),302)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(shuffle)"
      ],
      "metadata": {
        "id": "RVODRx17bZiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e0c52b-ae1a-490d-c868-c3d9857753ba"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[147  46 211  76 128  15 260 200 107 294  85 203  81 279 212 230 262 135\n",
            " 179 113 297 253  62  18 202 291  83  96 231 194  62  89 254 267 132 225\n",
            " 144 195  12 102  73 192 200 299 226 121 183  27  32 228 199 241 149 279\n",
            "   8 249 223  69  79  13 273  81  15 102 163 191  76 183 120  21 230 134\n",
            " 124  96  71 137 225 157  72 235 113 223 102 271  54  30 301 101  76 291\n",
            " 294 184 109 167  11 188 292 160   8 114 218 180 196  75 162 288  69  82\n",
            " 250  68 288  37 193 104 142 256  84 265  50  61 281 121 276 278 148 145\n",
            "  89 219  19  25  70 170 190  95 258  12 158 147 168 182 287 286 100 217\n",
            "  79 168 258 194   4 192  11 215 272  92 271 102  44  90  98 279   1 149\n",
            " 109 276  74  27 151   8 232 102 280  24 259  87  69  91 167  25  65  59\n",
            " 173 234 220  85 209 189 103 153 237  93 153  11  63 226  68 291  96 223\n",
            " 107 236  95  21 300  38 229 253 251 128 219 250 122  90 174  40 253 217\n",
            " 241  81 239 287 199  71  16  76 182 210 261 165 123 153  75 183 288 232\n",
            "  18 197   8 242 197 128 205  46 127 195 198  13 254 266  36 231 189  41\n",
            " 165  69  88  80 200   0 293 217 238 109  65 263  53   5  41  87 124 101\n",
            " 192  65 280   8 174  37  27  33 123 295  69  25 107  96 191 196 157 279\n",
            " 288 162 138 259 136 279 238 214 110 218 270 279  77 132]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "M95GVXYMUfZ-"
      },
      "outputs": [],
      "source": [
        "ytrain_global = np.array(data['label'].tolist())\n",
        "xtrain_global = np.array(data['text'].tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataloader"
      ],
      "metadata": {
        "id": "w8hE_0AQLLjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.model_selection as model_selection"
      ],
      "metadata": {
        "id": "WFYvlhkTLZF8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item"
      ],
      "metadata": {
        "id": "o9xKlzZ7K_HS"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"emocoes3.0.csv\")\n",
        "\n",
        "texts = df['text'].tolist()\n",
        "labels = df['label'].tolist()"
      ],
      "metadata": {
        "id": "B7cN6OOhLG07"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
        "\n",
        "encodings = tokenizer(texts, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "wOzeagdKLhuY"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TextDataset(encodings, labels)"
      ],
      "metadata": {
        "id": "IPr-fw2pLwzW"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "for batch in dataloader:\n",
        "    print(batch['input_ids'].shape)\n",
        "    print(batch['attention_mask'].shape)\n",
        "    print(batch['labels'])\n",
        "    break"
      ],
      "metadata": {
        "id": "GfkRiX7LMCjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97b8d0c6-291a-47d7-aad7-420321a64109"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 23])\n",
            "torch.Size([16, 23])\n",
            "tensor([1, 0, 1, 1, 2, 2, 0, 0, 2, 2, 1, 1, 2, 0, 1, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-f2051a2d5966>:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#---------------------------------"
      ],
      "metadata": {
        "id": "zELlMU9SLhfZ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "cGthp7btjrD6"
      },
      "outputs": [],
      "source": [
        "xtrain, xval, ytrain, yval = model_selection.train_test_split(\n",
        "    xtrain_global,\n",
        "    ytrain_global,\n",
        "    test_size=0.15,\n",
        "    random_state=42,\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain_final, xval, ytrain_final, yval = model_selection.train_test_split(\n",
        "    xtrain,\n",
        "    ytrain,\n",
        "    test_size=0.176,  # test_size calculado como 0.15 / (0.70 + 0.15) ≈ 0.176\n",
        "    random_state=42,\n",
        "    shuffle=True)"
      ],
      "metadata": {
        "id": "U7SRBIbHdn20"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "TiaEapoX9fG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ebae997-6d03-420f-cf30-e671e5827d89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('A experiência superou todas as minhas expectativas.', 2)\n",
            "('O aplicativo é confuso e pouco funcional.', 0)\n",
            "('A apresentação foi clara e detalhada.', 2)\n"
          ]
        }
      ],
      "source": [
        "for v in zip(xtrain[:3],ytrain[:3]):\n",
        "    print(v)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain = [str(x) for x in xtrain]\n",
        "xval = [str(x) for x in xval]"
      ],
      "metadata": {
        "id": "OrZejlwPWWuz"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(xtrain, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
        "val_encodings = tokenizer(xval, truncation=True, padding=True, max_length=512, return_tensors='pt')"
      ],
      "metadata": {
        "id": "BBeg8cf0TkYv"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_encodings)\n",
        "print(val_encodings)"
      ],
      "metadata": {
        "id": "dwqppWItTzuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84dc5fac-54c1-4096-a25d-ac51e2906219"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[    0,   250, 34433,  ...,     1,     1,     1],\n",
            "        [    0,   673,    10,  ...,     1,     1,     1],\n",
            "        [    0,   250,  6256,  ...,     1,     1,     1],\n",
            "        ...,\n",
            "        [    0,   673, 18215,  ...,     1,     1,     1],\n",
            "        [    0,   487,  4214,  ...,     1,     1,     1],\n",
            "        [    0,   250,  4600,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
            "{'input_ids': tensor([[    0,   673,  3653,  ...,     1,     1,     1],\n",
            "        [    0,   673, 25822,  ...,     1,     1,     1],\n",
            "        [    0,   673, 25771,  ...,     1,     1,     1],\n",
            "        ...,\n",
            "        [    0,   597,  1322,  ...,     1,     1,     1],\n",
            "        [    0,   673,   579,  ...,     1,     1,     1],\n",
            "        [    0, 23791,  7252,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "IIXUoH5zjzNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac5d39a1-3867-4b88-d1bc-05ac945e81fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "train_encodings.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "qhPhYVy5kCzQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d007c21a-1794-456e-ee3b-09c95a46ce92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([    0,   250, 34433,   118,  5563, 11326,   493,  2422,  1438,     7,\n",
              "          417,   281,    25,  5251,  7333,  1057,   415, 20559,     4,     2,\n",
              "            1,     1,     1])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "train_encodings['input_ids'][0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "label_to_id = {'0': 0, '1': 1, '2': 2}"
      ],
      "metadata": {
        "id": "CpMuKZXNWRX4"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "e0v6SonpkD73"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {\n",
        "            'input_ids': self.encodings['input_ids'][idx],\n",
        "            'attention_mask': self.encodings['attention_mask'][idx]\n",
        "        }\n",
        "        label = self.labels[idx]\n",
        "        return item, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "k7ToplVAkZYu"
      },
      "outputs": [],
      "source": [
        "ret=train_encodings.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "-sBluXDxkTzF"
      },
      "outputs": [],
      "source": [
        "ds_train = MyDataset(train_encodings,ytrain)\n",
        "ds_val   = MyDataset(val_encodings,yval)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Labels únicas no dataset original:\", np.unique(ytrain_global))"
      ],
      "metadata": {
        "id": "zEDLDRyggfOR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7a2c069-11a2-41ee-a0c7-9ff0aa14daa6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels únicas no dataset original: [0 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(ytrain,return_counts=True)"
      ],
      "metadata": {
        "id": "4nDMqHb932uz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14696791-dc54-44d8-f18e-f0192ee4a232"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2]), array([83, 85, 88]))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "myvv1f8KkXhy"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "hJ9Wya45kbn1"
      },
      "outputs": [],
      "source": [
        "dl_train = DataLoader(ds_train,batch_size=8)\n",
        "dl_eval  = DataLoader(ds_val,batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "leLZtyGCkn_z"
      },
      "outputs": [],
      "source": [
        "x,y = next(iter(dl_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "oGQo2IYrkcHH"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "prQfjbJUwxKg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bf73762-06cc-4f52-894f-ae45341293a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "0cmGNuDlkeA2"
      },
      "outputs": [],
      "source": [
        "batch = {k: v.to(device) for k, v in x.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "npVuzTlQkfJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b79c60b-cd95-4530-f253-c1735dfbb71c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier(\n",
              "  (bert): RobertaForSequenceClassification(\n",
              "    (roberta): RobertaModel(\n",
              "      (embeddings): RobertaEmbeddings(\n",
              "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "        (token_type_embeddings): Embedding(1, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): RobertaEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0-11): 12 x RobertaLayer(\n",
              "            (attention): RobertaAttention(\n",
              "              (self): RobertaSdpaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): RobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): RobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): RobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (classifier): RobertaClassificationHead(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (cls): Linear(in_features=768, out_features=400, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (cls2): Linear(in_features=400, out_features=3, bias=True)\n",
              "  (gelu): GELU(approximate='none')\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape de outputs[0]:\", out[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROZm3I71I0dc",
        "outputId": "6653b551-32df-46da-ce00-e1f369545347"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape de outputs[0]: torch.Size([1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#alterando a ultima camada\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"cardiffnlp/twitter-roberta-base-sentiment\",\n",
        "    num_labels=3,\n",
        "    output_hidden_states=True\n",
        ")"
      ],
      "metadata": {
        "id": "8sEU8pAbJUC-"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch = {k: v.to(device) for k, v in batch.items()}"
      ],
      "metadata": {
        "id": "T57krkHkKeGu"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "SrkMyjHMkqsY"
      },
      "outputs": [],
      "source": [
        "out = model(**batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "2QdIqbBOw8TV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13500a92-2958-4578-8e1a-64bce3ae66b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput(loss=None, logits=tensor([[-0.6478,  1.6054, -1.0010],\n",
              "        [-0.4024,  1.4059, -0.9758],\n",
              "        [-0.3498,  1.3426, -0.9752],\n",
              "        [-0.4288,  1.2747, -0.8077],\n",
              "        [-0.3886,  1.2897, -0.8745],\n",
              "        [-0.4749,  1.3529, -0.9024],\n",
              "        [ 0.0984,  1.1536, -1.2275],\n",
              "        [-0.1621,  1.4379, -1.3208]], device='cuda:0',\n",
              "       grad_fn=<AddmmBackward0>), hidden_states=(tensor([[[ 1.3776e-01, -7.9922e-02, -4.4657e-03,  ..., -4.6888e-02,\n",
              "           5.8684e-02,  4.2997e-02],\n",
              "         [ 6.8670e-02, -1.2839e-01,  1.3194e-01,  ..., -5.3267e-02,\n",
              "          -2.8847e-01,  5.0959e-01],\n",
              "         [ 1.1501e-02, -3.0653e-01, -6.3176e-02,  ..., -3.8221e-01,\n",
              "          -5.7750e-01,  4.3071e-01],\n",
              "         ...,\n",
              "         [-5.0868e-01,  5.0693e-01,  8.0038e-04,  ..., -3.9927e-01,\n",
              "           3.1462e-01, -3.6372e-01],\n",
              "         [-5.0868e-01,  5.0693e-01,  8.0038e-04,  ..., -3.9927e-01,\n",
              "           3.1462e-01, -3.6372e-01],\n",
              "         [-5.0868e-01,  5.0693e-01,  8.0038e-04,  ..., -3.9927e-01,\n",
              "           3.1462e-01, -3.6372e-01]],\n",
              "\n",
              "        [[ 1.3776e-01, -7.9922e-02, -4.4657e-03,  ..., -4.6888e-02,\n",
              "           5.8684e-02,  4.2997e-02],\n",
              "         [ 4.0190e-01,  1.0551e-01,  4.4213e-01,  ..., -2.3731e-01,\n",
              "          -3.9673e-01, -5.6764e-02],\n",
              "         [-2.7605e-01, -1.5337e-01, -6.7846e-03,  ...,  1.4157e-01,\n",
              "          -2.0331e-01,  5.1725e-01],\n",
              "         ...,\n",
              "         [-5.0868e-01,  5.0693e-01,  8.0038e-04,  ..., -3.9927e-01,\n",
              "           3.1462e-01, -3.6372e-01],\n",
              "         [-5.0868e-01,  5.0693e-01,  8.0038e-04,  ..., -3.9927e-01,\n",
              "           3.1462e-01, -3.6372e-01],\n",
              "         [-5.0868e-01,  5.0693e-01,  8.0038e-04,  ..., -3.9927e-01,\n",
              "           3.1462e-01, -3.6372e-01]],\n",
              "\n",
              "        [[ 1.3776e-01, -7.9922e-02, -4.4657e-03,  ..., -4.6888e-02,\n",
              "           5.8684e-02,  4.2997e-02],\n",
              "         [ 6.8670e-02, -1.2839e-01,  1.3194e-01,  ..., -5.3267e-02,\n",
              "          -2.8847e-01,  5.0959e-01],\n",
              "         [-3.1909e-01, -1.4965e-01,  3.6552e-02,  ..., -3.9596e-01,\n",
              "           5.4940e-02, -3.7154e-01],\n",
              "         ...,\n",
              "         [-5.0868e-01,  5.0693e-01,  8.0038e-04,  ..., -3.9927e-01,\n",
              "           3.1462e-01, -3.6372e-01],\n",
              "         [-5.0868e-01,  5.0693e-01,  8.0038e-04,  ..., -3.9927e-01,\n",
              "           3.1462e-01, -3.6372e-01],\n",
              "         [-5.0868e-01,  5.0693e-01,  8.0038e-04,  ..., -3.9927e-01,\n",
              "           3.1462e-01, -3.6372e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 1.3776e-01, -7.9922e-02, -4.4657e-03,  ..., -4.6888e-02,\n",
              "           5.8684e-02,  4.2997e-02],\n",
              "         [ 1.0205e-01,  3.6886e-02,  3.7842e-01,  ...,  2.6543e-01,\n",
              "          -6.8755e-01,  3.6877e-01],\n",
              "         [-2.1205e-01, -1.2898e-01,  3.2498e-01,  ..., -2.1539e-02,\n",
              "          -7.5222e-01,  3.3893e-02],\n",
              "         ...,\n",
              "         [-5.0868e-01,  5.0693e-01,  8.0038e-04,  ..., -3.9927e-01,\n",
              "           3.1462e-01, -3.6372e-01],\n",
              "         [-5.0868e-01,  5.0693e-01,  8.0038e-04,  ..., -3.9927e-01,\n",
              "           3.1462e-01, -3.6372e-01],\n",
              "         [-5.0868e-01,  5.0693e-01,  8.0038e-04,  ..., -3.9927e-01,\n",
              "           3.1462e-01, -3.6372e-01]],\n",
              "\n",
              "        [[ 1.3776e-01, -7.9922e-02, -4.4657e-03,  ..., -4.6888e-02,\n",
              "           5.8684e-02,  4.2997e-02],\n",
              "         [ 4.0190e-01,  1.0551e-01,  4.4213e-01,  ..., -2.3731e-01,\n",
              "          -3.9673e-01, -5.6764e-02],\n",
              "         [-2.3662e-02,  6.0886e-01, -4.3714e-01,  ...,  2.6583e-01,\n",
              "           7.1182e-02,  4.2304e-01],\n",
              "         ...,\n",
              "         [-5.0868e-01,  5.0693e-01,  8.0038e-04,  ..., -3.9927e-01,\n",
              "           3.1462e-01, -3.6372e-01],\n",
              "         [-5.0868e-01,  5.0693e-01,  8.0038e-04,  ..., -3.9927e-01,\n",
              "           3.1462e-01, -3.6372e-01],\n",
              "         [-5.0868e-01,  5.0693e-01,  8.0038e-04,  ..., -3.9927e-01,\n",
              "           3.1462e-01, -3.6372e-01]],\n",
              "\n",
              "        [[ 1.3776e-01, -7.9922e-02, -4.4657e-03,  ..., -4.6888e-02,\n",
              "           5.8684e-02,  4.2997e-02],\n",
              "         [ 1.7865e-01, -1.6749e-01,  5.9366e-01,  ...,  1.1023e-01,\n",
              "          -1.9632e-01,  3.5156e-01],\n",
              "         [ 7.6262e-02, -5.2967e-01,  1.0272e-01,  ..., -5.0450e-01,\n",
              "          -2.8011e-02,  1.1460e-01],\n",
              "         ...,\n",
              "         [ 2.0598e-01, -1.3536e-02,  1.6822e-01,  ..., -7.3707e-01,\n",
              "          -1.0767e-01, -9.6780e-02],\n",
              "         [-1.9263e-04, -1.1160e-01,  8.7229e-02,  ...,  4.2813e-01,\n",
              "           3.5775e-03, -2.4500e-01],\n",
              "         [-5.0868e-01,  5.0693e-01,  8.0038e-04,  ..., -3.9927e-01,\n",
              "           3.1462e-01, -3.6372e-01]]], device='cuda:0',\n",
              "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0176,  0.0530,  0.0123,  ..., -0.0612,  0.0895, -0.0972],\n",
              "         [ 0.0741, -0.4079,  0.4590,  ..., -0.3668,  0.2349,  0.8032],\n",
              "         [-0.0134,  0.0790,  0.2903,  ..., -0.9915, -0.2279,  0.8864],\n",
              "         ...,\n",
              "         [-0.0056,  0.3510,  0.2888,  ..., -0.1763, -0.1814,  0.2502],\n",
              "         [-0.0056,  0.3510,  0.2888,  ..., -0.1763, -0.1814,  0.2502],\n",
              "         [-0.0056,  0.3510,  0.2888,  ..., -0.1763, -0.1814,  0.2502]],\n",
              "\n",
              "        [[ 0.0381,  0.0406,  0.0071,  ..., -0.0475,  0.0806, -0.0815],\n",
              "         [ 0.3940,  0.1595,  0.8458,  ..., -0.2956, -0.1600, -0.0719],\n",
              "         [-0.3622, -0.3563,  0.0423,  ...,  0.3886, -0.1942,  0.7182],\n",
              "         ...,\n",
              "         [-0.0352,  0.3811,  0.3250,  ..., -0.1879, -0.1222,  0.3285],\n",
              "         [-0.0352,  0.3811,  0.3250,  ..., -0.1879, -0.1222,  0.3285],\n",
              "         [-0.0352,  0.3811,  0.3250,  ..., -0.1879, -0.1222,  0.3285]],\n",
              "\n",
              "        [[ 0.0409,  0.0626, -0.0043,  ..., -0.0450,  0.0889, -0.0952],\n",
              "         [ 0.0431, -0.6059,  0.4672,  ..., -0.3228,  0.2701,  0.9676],\n",
              "         [-0.0185,  0.3991,  0.2569,  ..., -0.6012,  0.2201, -0.8536],\n",
              "         ...,\n",
              "         [-0.0783,  0.4217,  0.2267,  ..., -0.1383, -0.1587,  0.2703],\n",
              "         [-0.0783,  0.4217,  0.2267,  ..., -0.1383, -0.1587,  0.2703],\n",
              "         [-0.0783,  0.4217,  0.2267,  ..., -0.1383, -0.1587,  0.2703]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.0292,  0.0513,  0.0210,  ..., -0.0404,  0.0769, -0.1089],\n",
              "         [ 0.0661,  0.4953,  0.5597,  ...,  0.4910, -0.4622,  0.7084],\n",
              "         [ 0.2292,  0.0248,  1.1869,  ..., -0.4094, -0.4183,  0.1697],\n",
              "         ...,\n",
              "         [-0.0815,  0.3798,  0.2874,  ..., -0.1084, -0.1431,  0.2192],\n",
              "         [-0.0815,  0.3798,  0.2874,  ..., -0.1084, -0.1431,  0.2192],\n",
              "         [-0.0815,  0.3798,  0.2874,  ..., -0.1084, -0.1431,  0.2192]],\n",
              "\n",
              "        [[ 0.0153,  0.0874, -0.0031,  ..., -0.0143,  0.0903, -0.0869],\n",
              "         [ 0.6037, -0.0289,  1.0464,  ..., -0.2590,  0.2085, -0.3476],\n",
              "         [ 0.4554,  1.7315, -0.8949,  ...,  0.9426,  0.4554,  0.4153],\n",
              "         ...,\n",
              "         [-0.1231,  0.3133,  0.1366,  ..., -0.1939, -0.2502,  0.3586],\n",
              "         [-0.1231,  0.3133,  0.1366,  ..., -0.1939, -0.2502,  0.3586],\n",
              "         [-0.1231,  0.3133,  0.1366,  ..., -0.1939, -0.2502,  0.3586]],\n",
              "\n",
              "        [[ 0.0207,  0.0976,  0.0094,  ..., -0.0275,  0.0946, -0.0902],\n",
              "         [ 0.2175, -0.0260,  0.8280,  ...,  0.3111,  0.3296,  0.6401],\n",
              "         [ 0.3752, -0.2317,  0.6630,  ..., -1.0717,  0.2701,  0.3933],\n",
              "         ...,\n",
              "         [ 0.0261,  0.2325,  0.2050,  ..., -0.6160,  0.1982, -0.2434],\n",
              "         [-0.4184,  0.2239,  0.1705,  ...,  0.4551,  0.1721, -0.5010],\n",
              "         [-0.1331,  0.4353,  0.1583,  ..., -0.0948, -0.1651,  0.3239]]],\n",
              "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 5.6603e-02,  3.1658e-02,  1.7724e-02,  ..., -3.0957e-02,\n",
              "           4.6858e-02, -4.1621e-02],\n",
              "         [ 2.9857e-02, -3.8653e-01,  3.8636e-01,  ..., -5.6647e-01,\n",
              "           4.3626e-01,  8.2455e-01],\n",
              "         [ 2.2063e-01,  3.5895e-01,  5.1376e-01,  ..., -1.3581e+00,\n",
              "          -1.1320e-01,  3.7482e-01],\n",
              "         ...,\n",
              "         [-4.2664e-02,  4.1613e-01, -1.8170e-02,  ...,  1.2454e-01,\n",
              "           2.8016e-01,  1.1336e-01],\n",
              "         [-4.2664e-02,  4.1613e-01, -1.8170e-02,  ...,  1.2454e-01,\n",
              "           2.8016e-01,  1.1336e-01],\n",
              "         [-4.2664e-02,  4.1613e-01, -1.8170e-02,  ...,  1.2454e-01,\n",
              "           2.8016e-01,  1.1336e-01]],\n",
              "\n",
              "        [[ 6.6561e-02,  2.9315e-02,  1.9468e-02,  ..., -2.5629e-02,\n",
              "           4.5799e-02, -3.4866e-02],\n",
              "         [ 3.0409e-01, -6.0765e-02,  9.0815e-01,  ..., -1.0931e-01,\n",
              "           5.7474e-01,  3.8619e-01],\n",
              "         [-2.0266e-01, -5.8773e-01,  3.0388e-01,  ...,  8.5662e-02,\n",
              "          -2.6309e-01,  8.0335e-01],\n",
              "         ...,\n",
              "         [ 4.8507e-02,  3.9108e-01, -4.6742e-02,  ...,  3.0675e-01,\n",
              "           4.4794e-01,  1.6631e-01],\n",
              "         [ 4.8507e-02,  3.9108e-01, -4.6742e-02,  ...,  3.0675e-01,\n",
              "           4.4794e-01,  1.6631e-01],\n",
              "         [ 4.8507e-02,  3.9108e-01, -4.6742e-02,  ...,  3.0675e-01,\n",
              "           4.4794e-01,  1.6631e-01]],\n",
              "\n",
              "        [[ 5.7753e-02,  3.7119e-02,  1.2414e-02,  ..., -2.9533e-02,\n",
              "           4.5826e-02, -3.2039e-02],\n",
              "         [-6.3408e-02, -5.4750e-01,  1.9712e-01,  ..., -5.3169e-01,\n",
              "           5.7813e-01,  8.2198e-01],\n",
              "         [ 1.1233e-01,  4.4974e-01,  6.2740e-01,  ..., -4.9464e-01,\n",
              "           2.1585e-01, -1.0066e+00],\n",
              "         ...,\n",
              "         [ 7.6488e-02,  4.7571e-01,  7.2117e-02,  ...,  2.6052e-01,\n",
              "           2.5512e-01,  5.0534e-02],\n",
              "         [ 7.6488e-02,  4.7571e-01,  7.2117e-02,  ...,  2.6052e-01,\n",
              "           2.5512e-01,  5.0534e-02],\n",
              "         [ 7.6488e-02,  4.7571e-01,  7.2117e-02,  ...,  2.6052e-01,\n",
              "           2.5512e-01,  5.0534e-02]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 5.5176e-02,  3.0439e-02,  2.3838e-02,  ..., -2.7069e-02,\n",
              "           4.4746e-02, -4.1553e-02],\n",
              "         [ 3.6503e-01,  4.3740e-01,  5.6965e-01,  ...,  3.6143e-01,\n",
              "          -2.3984e-01,  2.9015e-01],\n",
              "         [-2.4420e-01, -4.9872e-01,  1.1644e+00,  ..., -1.1638e-01,\n",
              "           6.1519e-02,  3.3794e-01],\n",
              "         ...,\n",
              "         [-1.0002e-01,  5.7980e-01, -3.7543e-03,  ...,  1.7483e-01,\n",
              "           1.4422e-01, -1.3016e-01],\n",
              "         [-1.0002e-01,  5.7980e-01, -3.7543e-03,  ...,  1.7483e-01,\n",
              "           1.4422e-01, -1.3016e-01],\n",
              "         [-1.0002e-01,  5.7980e-01, -3.7543e-03,  ...,  1.7483e-01,\n",
              "           1.4422e-01, -1.3016e-01]],\n",
              "\n",
              "        [[ 5.3968e-02,  4.6817e-02,  9.5666e-03,  ..., -2.5780e-02,\n",
              "           4.6488e-02, -2.6239e-02],\n",
              "         [-3.2659e-01, -2.3800e-01,  9.3517e-01,  ..., -7.0213e-03,\n",
              "           4.6678e-01,  1.3346e-03],\n",
              "         [ 3.6240e-01,  2.2196e+00, -7.8945e-01,  ...,  9.9676e-01,\n",
              "           1.1268e+00,  1.1919e-01],\n",
              "         ...,\n",
              "         [ 3.2291e-02,  4.1395e-01, -1.4333e-01,  ...,  1.5045e-01,\n",
              "           1.1660e-01,  1.1762e-01],\n",
              "         [ 3.2291e-02,  4.1395e-01, -1.4333e-01,  ...,  1.5045e-01,\n",
              "           1.1660e-01,  1.1762e-01],\n",
              "         [ 3.2291e-02,  4.1395e-01, -1.4333e-01,  ...,  1.5045e-01,\n",
              "           1.1660e-01,  1.1762e-01]],\n",
              "\n",
              "        [[ 5.9327e-02,  4.7180e-02,  2.0692e-02,  ..., -2.4793e-02,\n",
              "           4.8059e-02, -3.8358e-02],\n",
              "         [ 8.0900e-02, -1.9708e-01,  7.4132e-01,  ...,  2.7076e-01,\n",
              "           6.9757e-01,  6.5413e-01],\n",
              "         [ 3.6049e-01, -9.0179e-02,  8.1766e-01,  ..., -1.0023e+00,\n",
              "           3.8129e-01, -4.5488e-02],\n",
              "         ...,\n",
              "         [-2.4763e-01,  2.3282e-01,  2.2837e-02,  ..., -4.9929e-01,\n",
              "           8.8881e-02, -1.6795e-01],\n",
              "         [-4.8558e-01,  2.4391e-01,  4.0105e-01,  ...,  7.0431e-01,\n",
              "           1.5027e-01, -3.3474e-01],\n",
              "         [-6.0455e-02,  5.4994e-01, -8.1860e-02,  ...,  2.0175e-01,\n",
              "          -3.3534e-02,  1.2381e-01]]], device='cuda:0',\n",
              "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 5.0224e-02,  1.2208e-02,  2.4784e-02,  ..., -5.2803e-02,\n",
              "           1.0377e-02,  3.8671e-02],\n",
              "         [ 2.4451e-01, -5.5112e-01,  5.2684e-02,  ..., -7.5483e-01,\n",
              "           3.4814e-01,  6.9523e-01],\n",
              "         [ 2.2789e-01,  1.9199e-01,  5.2200e-01,  ..., -1.3820e+00,\n",
              "          -5.4110e-01,  2.8199e-01],\n",
              "         ...,\n",
              "         [-6.5377e-02,  1.0421e-01, -2.4631e-01,  ...,  8.4095e-02,\n",
              "           6.3496e-01,  4.1549e-01],\n",
              "         [-6.5377e-02,  1.0421e-01, -2.4631e-01,  ...,  8.4095e-02,\n",
              "           6.3496e-01,  4.1549e-01],\n",
              "         [-6.5377e-02,  1.0421e-01, -2.4631e-01,  ...,  8.4095e-02,\n",
              "           6.3496e-01,  4.1549e-01]],\n",
              "\n",
              "        [[ 6.3634e-02,  1.4895e-02,  2.7954e-02,  ..., -4.9589e-02,\n",
              "           3.6377e-02,  3.6931e-02],\n",
              "         [ 4.1715e-01, -4.7993e-01,  4.5736e-01,  ...,  3.4428e-02,\n",
              "           5.3063e-01,  3.7363e-01],\n",
              "         [ 1.1028e-01, -4.4100e-01,  2.4806e-01,  ...,  1.7903e-01,\n",
              "          -2.6081e-01,  4.0706e-01],\n",
              "         ...,\n",
              "         [-1.4192e-01,  8.4381e-02, -2.8261e-02,  ...,  3.3812e-01,\n",
              "           7.0781e-01,  5.0347e-01],\n",
              "         [-1.4192e-01,  8.4381e-02, -2.8261e-02,  ...,  3.3812e-01,\n",
              "           7.0781e-01,  5.0347e-01],\n",
              "         [-1.4192e-01,  8.4381e-02, -2.8261e-02,  ...,  3.3812e-01,\n",
              "           7.0781e-01,  5.0347e-01]],\n",
              "\n",
              "        [[ 5.6838e-02,  7.2581e-03,  6.6214e-03,  ..., -4.9044e-02,\n",
              "           2.4343e-02,  5.0209e-02],\n",
              "         [ 3.3323e-01, -5.5982e-01,  1.5500e-01,  ..., -8.0280e-01,\n",
              "           3.4904e-01,  6.7049e-01],\n",
              "         [ 2.2912e-01,  3.6955e-01,  5.6186e-01,  ..., -7.5563e-01,\n",
              "          -1.2224e-01, -8.7868e-01],\n",
              "         ...,\n",
              "         [-1.1885e-02,  8.7264e-02, -1.0926e-01,  ...,  2.5839e-01,\n",
              "           6.3977e-01,  3.7371e-01],\n",
              "         [-1.1885e-02,  8.7264e-02, -1.0926e-01,  ...,  2.5839e-01,\n",
              "           6.3977e-01,  3.7371e-01],\n",
              "         [-1.1885e-02,  8.7264e-02, -1.0926e-01,  ...,  2.5839e-01,\n",
              "           6.3977e-01,  3.7371e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 5.7061e-02,  2.3687e-03,  2.8351e-02,  ..., -3.6060e-02,\n",
              "           3.5304e-02,  3.2893e-02],\n",
              "         [ 2.9587e-01,  3.2821e-01,  3.8960e-01,  ...,  2.2512e-01,\n",
              "          -1.9937e-02,  4.2693e-01],\n",
              "         [-1.2120e-01, -2.1929e-01,  6.6267e-01,  ..., -7.4507e-01,\n",
              "          -3.9356e-01, -2.0404e-01],\n",
              "         ...,\n",
              "         [ 1.5156e-01,  2.8234e-01, -1.5518e-01,  ...,  2.0241e-01,\n",
              "           7.0201e-01,  2.0403e-01],\n",
              "         [ 1.5156e-01,  2.8234e-01, -1.5518e-01,  ...,  2.0241e-01,\n",
              "           7.0201e-01,  2.0403e-01],\n",
              "         [ 1.5156e-01,  2.8234e-01, -1.5518e-01,  ...,  2.0241e-01,\n",
              "           7.0201e-01,  2.0403e-01]],\n",
              "\n",
              "        [[ 5.0249e-02,  2.3182e-02,  1.3313e-02,  ..., -3.5008e-02,\n",
              "           4.1251e-02,  4.5196e-02],\n",
              "         [ 1.8377e-01, -5.0406e-01,  3.7863e-01,  ..., -9.4998e-03,\n",
              "           5.7476e-01,  2.0242e-03],\n",
              "         [ 3.4274e-01,  2.0853e+00, -5.7195e-01,  ...,  1.0109e+00,\n",
              "           8.5675e-01, -4.8678e-02],\n",
              "         ...,\n",
              "         [-5.2775e-02,  9.1546e-02, -2.8124e-01,  ...,  1.9644e-01,\n",
              "           6.0474e-01,  3.6288e-01],\n",
              "         [-5.2775e-02,  9.1546e-02, -2.8124e-01,  ...,  1.9644e-01,\n",
              "           6.0474e-01,  3.6288e-01],\n",
              "         [-5.2775e-02,  9.1546e-02, -2.8124e-01,  ...,  1.9644e-01,\n",
              "           6.0474e-01,  3.6288e-01]],\n",
              "\n",
              "        [[ 5.7585e-02,  1.6648e-02,  2.4669e-02,  ..., -4.2880e-02,\n",
              "           3.7729e-02,  3.4645e-02],\n",
              "         [ 1.0456e-01, -3.3992e-01,  7.1839e-01,  ...,  3.1703e-01,\n",
              "           3.0666e-01,  5.6118e-01],\n",
              "         [ 5.6526e-01, -3.8703e-01,  3.8563e-01,  ..., -8.8101e-01,\n",
              "           2.4224e-01, -1.8250e-01],\n",
              "         ...,\n",
              "         [ 2.0542e-01,  3.7468e-01, -1.8712e-01,  ..., -5.3073e-01,\n",
              "           2.2450e-01, -9.4332e-02],\n",
              "         [ 2.0204e-02,  1.7802e-01,  4.4073e-02,  ...,  9.5863e-02,\n",
              "           3.8225e-01,  2.1178e-02],\n",
              "         [ 1.2492e-03, -5.1331e-03,  1.3630e-02,  ...,  1.1101e-02,\n",
              "           5.7445e-01,  2.2927e-01]]], device='cuda:0',\n",
              "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-7.7824e-02, -4.6071e-02,  3.4858e-02,  ..., -3.3940e-02,\n",
              "           3.4938e-03,  3.9967e-02],\n",
              "         [ 1.7680e-01, -5.7570e-01,  2.5254e-01,  ..., -7.0340e-01,\n",
              "           3.7303e-01,  6.1616e-01],\n",
              "         [-3.9469e-02,  7.9830e-03,  3.8113e-02,  ..., -1.1709e+00,\n",
              "          -2.6613e-01,  5.6504e-01],\n",
              "         ...,\n",
              "         [-8.5084e-02, -1.6886e-01, -1.1421e-01,  ...,  6.5754e-02,\n",
              "           2.7322e-01,  2.7119e-01],\n",
              "         [-8.5084e-02, -1.6886e-01, -1.1421e-01,  ...,  6.5754e-02,\n",
              "           2.7322e-01,  2.7119e-01],\n",
              "         [-8.5084e-02, -1.6886e-01, -1.1421e-01,  ...,  6.5754e-02,\n",
              "           2.7322e-01,  2.7119e-01]],\n",
              "\n",
              "        [[-8.5070e-02, -5.0178e-02,  4.4194e-02,  ..., -3.4779e-02,\n",
              "           1.3852e-02,  3.1466e-02],\n",
              "         [-2.5401e-01, -1.0151e+00,  5.9044e-01,  ...,  9.9961e-02,\n",
              "           1.8982e-01,  2.1622e-01],\n",
              "         [-2.0299e-01, -7.0993e-01,  3.2930e-01,  ...,  1.1612e-01,\n",
              "           7.1670e-02,  4.3038e-01],\n",
              "         ...,\n",
              "         [-1.3082e-01, -2.9432e-01,  7.8175e-02,  ...,  1.5086e-01,\n",
              "           3.5340e-01,  3.0202e-01],\n",
              "         [-1.3082e-01, -2.9432e-01,  7.8175e-02,  ...,  1.5086e-01,\n",
              "           3.5340e-01,  3.0202e-01],\n",
              "         [-1.3082e-01, -2.9432e-01,  7.8175e-02,  ...,  1.5086e-01,\n",
              "           3.5340e-01,  3.0202e-01]],\n",
              "\n",
              "        [[-8.7712e-02, -4.9478e-02,  3.2251e-02,  ..., -3.1074e-02,\n",
              "           8.9626e-03,  3.0472e-02],\n",
              "         [-1.9803e-01, -9.2746e-01,  2.8434e-01,  ..., -8.9719e-01,\n",
              "           3.3862e-01,  6.2655e-01],\n",
              "         [-9.8274e-02,  2.0361e-01,  1.4374e-01,  ..., -5.5107e-01,\n",
              "          -1.1545e-01, -7.9810e-01],\n",
              "         ...,\n",
              "         [-2.8111e-02, -3.0669e-01,  3.4934e-02,  ...,  1.3400e-01,\n",
              "           4.3496e-01,  1.6302e-01],\n",
              "         [-2.8111e-02, -3.0669e-01,  3.4934e-02,  ...,  1.3400e-01,\n",
              "           4.3496e-01,  1.6302e-01],\n",
              "         [-2.8111e-02, -3.0669e-01,  3.4934e-02,  ...,  1.3400e-01,\n",
              "           4.3496e-01,  1.6302e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-8.0580e-02, -5.7201e-02,  2.6078e-02,  ..., -1.4058e-02,\n",
              "           9.3627e-03,  1.5032e-02],\n",
              "         [-5.0654e-02, -2.5841e-01,  6.7285e-01,  ...,  1.5887e-01,\n",
              "           2.6067e-01,  3.9040e-01],\n",
              "         [-1.3996e-01, -8.3291e-01,  5.9705e-01,  ..., -8.7262e-01,\n",
              "          -1.8386e-02, -4.4175e-02],\n",
              "         ...,\n",
              "         [-1.7868e-01, -1.7846e-01,  2.9969e-02,  ...,  1.8299e-01,\n",
              "           2.4820e-01,  1.4247e-01],\n",
              "         [-1.7868e-01, -1.7846e-01,  2.9969e-02,  ...,  1.8299e-01,\n",
              "           2.4820e-01,  1.4247e-01],\n",
              "         [-1.7868e-01, -1.7846e-01,  2.9969e-02,  ...,  1.8299e-01,\n",
              "           2.4820e-01,  1.4247e-01]],\n",
              "\n",
              "        [[-7.8556e-02, -5.7622e-02,  2.7532e-02,  ..., -3.1308e-02,\n",
              "           1.9702e-02,  3.3256e-02],\n",
              "         [-3.7308e-01, -8.9100e-01,  4.7827e-01,  ...,  7.6613e-02,\n",
              "           2.7294e-01,  1.8422e-01],\n",
              "         [-1.4146e-01,  1.4974e+00, -3.7318e-01,  ...,  1.1464e+00,\n",
              "           3.1774e-01,  8.1814e-02],\n",
              "         ...,\n",
              "         [-1.3464e-01, -2.5947e-01, -2.5783e-02,  ...,  1.7671e-01,\n",
              "           3.1997e-01,  1.7380e-01],\n",
              "         [-1.3464e-01, -2.5947e-01, -2.5783e-02,  ...,  1.7671e-01,\n",
              "           3.1997e-01,  1.7380e-01],\n",
              "         [-1.3464e-01, -2.5947e-01, -2.5783e-02,  ...,  1.7671e-01,\n",
              "           3.1997e-01,  1.7380e-01]],\n",
              "\n",
              "        [[-6.3978e-02, -4.8549e-02,  3.2878e-02,  ..., -2.7972e-02,\n",
              "           2.5202e-02,  4.5424e-02],\n",
              "         [-2.0551e-02, -1.0891e+00,  5.3163e-01,  ...,  2.7154e-01,\n",
              "           5.8409e-01,  6.1712e-01],\n",
              "         [-3.2783e-02, -6.7271e-01,  1.0533e-01,  ..., -8.3691e-01,\n",
              "           4.2078e-01,  4.9258e-01],\n",
              "         ...,\n",
              "         [-1.0578e-01,  1.1531e-01, -1.1380e-01,  ..., -1.9153e-01,\n",
              "           1.2707e-01,  1.6224e-01],\n",
              "         [-1.7150e-02,  4.6851e-02, -2.8584e-02,  ..., -3.4985e-02,\n",
              "           1.1478e-01,  5.3709e-04],\n",
              "         [-1.7856e-01, -2.8493e-01,  1.4133e-01,  ...,  5.3233e-02,\n",
              "           3.8355e-01,  2.1366e-01]]], device='cuda:0',\n",
              "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 8.7975e-03, -1.3112e-01, -2.3293e-02,  ..., -4.1854e-03,\n",
              "          -1.5022e-01,  1.0483e-01],\n",
              "         [ 1.1843e-01, -3.6167e-01, -9.0203e-02,  ..., -5.6732e-01,\n",
              "           3.8511e-01,  3.6995e-01],\n",
              "         [ 2.6860e-01, -1.6082e-01, -1.5463e-01,  ..., -8.9490e-01,\n",
              "          -2.8217e-01,  7.5507e-01],\n",
              "         ...,\n",
              "         [ 2.5845e-02, -1.6193e-01,  7.1109e-02,  ...,  1.6142e-01,\n",
              "           9.6214e-02,  1.5338e-01],\n",
              "         [ 2.5845e-02, -1.6193e-01,  7.1109e-02,  ...,  1.6142e-01,\n",
              "           9.6214e-02,  1.5338e-01],\n",
              "         [ 2.5845e-02, -1.6193e-01,  7.1109e-02,  ...,  1.6142e-01,\n",
              "           9.6214e-02,  1.5338e-01]],\n",
              "\n",
              "        [[ 1.8844e-02, -1.3549e-01, -1.4313e-02,  ..., -1.0185e-02,\n",
              "          -1.5293e-01,  9.2095e-02],\n",
              "         [-3.2952e-01, -1.3345e+00,  1.9786e-01,  ...,  4.7406e-01,\n",
              "           4.3304e-01,  3.6571e-01],\n",
              "         [-3.9008e-01, -5.7409e-01,  2.6403e-01,  ...,  6.8277e-02,\n",
              "           2.5217e-02,  2.1699e-01],\n",
              "         ...,\n",
              "         [ 5.8588e-02, -3.7828e-01,  1.9003e-01,  ...,  2.7045e-01,\n",
              "           1.4530e-02,  1.6781e-01],\n",
              "         [ 5.8588e-02, -3.7828e-01,  1.9003e-01,  ...,  2.7045e-01,\n",
              "           1.4530e-02,  1.6781e-01],\n",
              "         [ 5.8588e-02, -3.7828e-01,  1.9003e-01,  ...,  2.7045e-01,\n",
              "           1.4530e-02,  1.6781e-01]],\n",
              "\n",
              "        [[ 9.0450e-03, -1.2647e-01, -6.2163e-03,  ..., -3.6371e-03,\n",
              "          -1.4846e-01,  1.0086e-01],\n",
              "         [-9.0025e-02, -7.4155e-01, -3.7941e-02,  ..., -6.4981e-01,\n",
              "           3.1231e-01,  3.9647e-01],\n",
              "         [-7.1355e-02,  1.1697e-01,  1.5180e-01,  ..., -4.0137e-01,\n",
              "          -2.9361e-01, -4.5131e-01],\n",
              "         ...,\n",
              "         [-7.6260e-02, -3.5639e-01,  2.7440e-01,  ...,  2.3734e-01,\n",
              "           1.5956e-01,  7.1478e-02],\n",
              "         [-7.6260e-02, -3.5639e-01,  2.7440e-01,  ...,  2.3734e-01,\n",
              "           1.5956e-01,  7.1478e-02],\n",
              "         [-7.6260e-02, -3.5639e-01,  2.7440e-01,  ...,  2.3734e-01,\n",
              "           1.5956e-01,  7.1478e-02]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 1.4872e-02, -1.2878e-01, -1.8457e-02,  ...,  1.7875e-03,\n",
              "          -1.4250e-01,  8.9595e-02],\n",
              "         [ 2.1804e-01, -5.6315e-02,  7.4831e-01,  ...,  2.5569e-01,\n",
              "           3.0020e-01,  5.0184e-01],\n",
              "         [-5.0388e-02, -1.0913e+00,  6.7410e-01,  ..., -4.8864e-01,\n",
              "           3.6940e-01,  1.0284e-01],\n",
              "         ...,\n",
              "         [ 4.9804e-02, -2.2927e-01,  2.5825e-01,  ...,  3.3522e-01,\n",
              "          -2.0372e-01,  1.8665e-01],\n",
              "         [ 4.9804e-02, -2.2927e-01,  2.5825e-01,  ...,  3.3522e-01,\n",
              "          -2.0372e-01,  1.8665e-01],\n",
              "         [ 4.9804e-02, -2.2927e-01,  2.5825e-01,  ...,  3.3522e-01,\n",
              "          -2.0372e-01,  1.8665e-01]],\n",
              "\n",
              "        [[ 8.7528e-03, -1.2776e-01, -9.6091e-03,  ..., -6.0336e-04,\n",
              "          -1.4683e-01,  8.6625e-02],\n",
              "         [-3.5016e-01, -1.2691e+00,  9.8060e-02,  ...,  3.3737e-01,\n",
              "           5.6307e-01,  1.3526e-02],\n",
              "         [-2.7028e-01,  1.3003e+00, -3.2594e-01,  ...,  1.0033e+00,\n",
              "           2.1783e-01, -1.4770e-01],\n",
              "         ...,\n",
              "         [-1.3080e-01, -3.0158e-01,  3.1864e-01,  ...,  2.8643e-01,\n",
              "           3.0408e-01,  2.1143e-01],\n",
              "         [-1.3080e-01, -3.0158e-01,  3.1864e-01,  ...,  2.8643e-01,\n",
              "           3.0408e-01,  2.1143e-01],\n",
              "         [-1.3080e-01, -3.0158e-01,  3.1864e-01,  ...,  2.8643e-01,\n",
              "           3.0408e-01,  2.1143e-01]],\n",
              "\n",
              "        [[ 1.5814e-02, -1.2250e-01, -1.0076e-02,  ..., -1.0997e-02,\n",
              "          -1.5035e-01,  9.6185e-02],\n",
              "         [-8.6873e-02, -1.1137e+00,  3.1705e-01,  ...,  6.4880e-01,\n",
              "          -1.2371e-01,  9.6504e-01],\n",
              "         [-4.0535e-01, -1.3287e+00,  6.0176e-01,  ..., -1.6947e-01,\n",
              "           2.9950e-01,  5.2665e-01],\n",
              "         ...,\n",
              "         [ 1.6494e-02,  7.1507e-02, -8.2565e-02,  ..., -1.4486e-01,\n",
              "           1.0821e-01,  3.8293e-03],\n",
              "         [-6.2501e-03,  2.7219e-02, -3.4121e-02,  ..., -7.0455e-02,\n",
              "           7.4893e-02, -2.2438e-02],\n",
              "         [ 1.1386e-01, -4.5935e-01,  1.6326e-01,  ...,  1.2734e-01,\n",
              "          -2.2743e-01,  1.4174e-01]]], device='cuda:0',\n",
              "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 3.5237e-02, -1.3824e-01, -3.1652e-02,  ..., -4.2761e-02,\n",
              "           3.5665e-03,  8.0019e-02],\n",
              "         [ 1.2323e-01, -4.0333e-01, -7.7702e-02,  ..., -4.4905e-01,\n",
              "           7.3610e-01,  6.2316e-02],\n",
              "         [-2.6697e-01, -5.3585e-01, -1.9532e-01,  ..., -9.1257e-01,\n",
              "           5.1578e-01,  4.6882e-01],\n",
              "         ...,\n",
              "         [ 3.3424e-01, -1.6015e-01, -2.6587e-01,  ...,  1.8926e-02,\n",
              "           1.4500e-01,  1.3732e-02],\n",
              "         [ 3.3424e-01, -1.6015e-01, -2.6587e-01,  ...,  1.8926e-02,\n",
              "           1.4500e-01,  1.3732e-02],\n",
              "         [ 3.3424e-01, -1.6015e-01, -2.6587e-01,  ...,  1.8926e-02,\n",
              "           1.4500e-01,  1.3732e-02]],\n",
              "\n",
              "        [[ 4.7370e-02, -1.4140e-01, -1.7502e-02,  ..., -5.0811e-02,\n",
              "          -1.5967e-02,  8.2379e-02],\n",
              "         [-1.8397e-01, -1.2593e+00, -6.6257e-02,  ...,  6.1635e-01,\n",
              "           4.1860e-01, -1.0661e-02],\n",
              "         [-1.9086e-01, -5.2471e-01,  4.1716e-01,  ..., -2.8592e-01,\n",
              "           4.4737e-01,  5.3916e-02],\n",
              "         ...,\n",
              "         [ 2.9476e-01, -1.3943e-01,  7.2887e-02,  ..., -7.3345e-03,\n",
              "          -9.1518e-02, -2.0617e-01],\n",
              "         [ 2.9476e-01, -1.3943e-01,  7.2887e-02,  ..., -7.3345e-03,\n",
              "          -9.1518e-02, -2.0617e-01],\n",
              "         [ 2.9476e-01, -1.3943e-01,  7.2887e-02,  ..., -7.3345e-03,\n",
              "          -9.1518e-02, -2.0617e-01]],\n",
              "\n",
              "        [[ 4.2629e-02, -1.2830e-01, -1.6882e-02,  ..., -4.5240e-02,\n",
              "          -9.5073e-03,  8.5256e-02],\n",
              "         [ 9.9268e-03, -4.8046e-01, -1.2686e-01,  ..., -5.7212e-01,\n",
              "           3.5753e-01, -1.1333e-02],\n",
              "         [ 3.5351e-02, -1.1106e-01,  1.1867e-01,  ..., -5.9152e-01,\n",
              "           3.9519e-01, -1.0556e-01],\n",
              "         ...,\n",
              "         [ 2.6487e-01, -1.1825e-01, -9.4114e-02,  ...,  5.1207e-02,\n",
              "           3.7410e-01, -1.1023e-01],\n",
              "         [ 2.6487e-01, -1.1825e-01, -9.4114e-02,  ...,  5.1207e-02,\n",
              "           3.7410e-01, -1.1023e-01],\n",
              "         [ 2.6487e-01, -1.1825e-01, -9.4114e-02,  ...,  5.1207e-02,\n",
              "           3.7410e-01, -1.1023e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 2.1081e-02, -1.2733e-01, -2.0458e-02,  ..., -3.0124e-02,\n",
              "          -2.3937e-03,  7.4949e-02],\n",
              "         [-1.8997e-01, -1.5324e-03,  4.4994e-01,  ...,  2.1424e-01,\n",
              "           7.9101e-01,  1.4328e-01],\n",
              "         [-2.4222e-01, -9.0496e-01,  2.6623e-01,  ..., -2.9962e-01,\n",
              "           7.6956e-01, -2.6580e-01],\n",
              "         ...,\n",
              "         [ 1.4979e-01,  1.4434e-02,  1.4158e-02,  ...,  1.5065e-01,\n",
              "           4.7183e-02, -1.3175e-01],\n",
              "         [ 1.4979e-01,  1.4434e-02,  1.4158e-02,  ...,  1.5065e-01,\n",
              "           4.7183e-02, -1.3175e-01],\n",
              "         [ 1.4979e-01,  1.4434e-02,  1.4158e-02,  ...,  1.5065e-01,\n",
              "           4.7183e-02, -1.3175e-01]],\n",
              "\n",
              "        [[ 3.6849e-02, -1.3027e-01, -2.6334e-02,  ..., -4.3988e-02,\n",
              "          -1.9273e-04,  7.9482e-02],\n",
              "         [-1.2782e-01, -1.3850e+00, -3.0403e-02,  ...,  4.7172e-01,\n",
              "           5.2914e-01, -1.8310e-01],\n",
              "         [ 1.7885e-01,  1.1489e+00,  3.2143e-01,  ...,  6.6865e-01,\n",
              "           5.3627e-01, -1.6708e-01],\n",
              "         ...,\n",
              "         [ 1.7298e-01, -8.8579e-02,  1.5943e-01,  ..., -9.9656e-02,\n",
              "           1.2790e-01, -1.1787e-01],\n",
              "         [ 1.7298e-01, -8.8579e-02,  1.5943e-01,  ..., -9.9656e-02,\n",
              "           1.2790e-01, -1.1787e-01],\n",
              "         [ 1.7298e-01, -8.8579e-02,  1.5943e-01,  ..., -9.9656e-02,\n",
              "           1.2790e-01, -1.1787e-01]],\n",
              "\n",
              "        [[ 4.9585e-02, -1.3656e-01, -1.6309e-02,  ..., -4.6236e-02,\n",
              "          -2.4917e-03,  8.8830e-02],\n",
              "         [-4.2137e-01, -1.0383e+00, -2.9418e-01,  ...,  8.1718e-01,\n",
              "           3.0685e-01,  4.9625e-01],\n",
              "         [-4.4562e-01, -1.2647e+00,  3.0736e-01,  ..., -5.0922e-02,\n",
              "           4.8562e-01,  4.7163e-02],\n",
              "         ...,\n",
              "         [-3.1376e-03, -1.2592e-02, -1.2675e-01,  ..., -7.7722e-02,\n",
              "           8.3341e-02, -4.7957e-03],\n",
              "         [ 1.0244e-04, -1.8924e-02, -8.9695e-02,  ..., -6.3362e-02,\n",
              "           5.3639e-02, -1.6217e-03],\n",
              "         [ 7.3235e-02, -3.0750e-01, -5.9017e-02,  ..., -7.6823e-02,\n",
              "           9.3076e-02, -3.3075e-01]]], device='cuda:0',\n",
              "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0315, -0.0850, -0.0316,  ..., -0.0555, -0.0528,  0.0280],\n",
              "         [-0.2375, -0.5637,  0.2955,  ..., -0.8199,  0.4899, -0.2267],\n",
              "         [-0.1443, -0.5823, -0.1542,  ..., -1.0691,  0.1796,  0.1690],\n",
              "         ...,\n",
              "         [ 0.2822, -0.3805,  0.0288,  ..., -0.0436,  0.2376, -0.3587],\n",
              "         [ 0.2822, -0.3805,  0.0288,  ..., -0.0436,  0.2376, -0.3587],\n",
              "         [ 0.2822, -0.3805,  0.0288,  ..., -0.0436,  0.2376, -0.3587]],\n",
              "\n",
              "        [[-0.0299, -0.0869, -0.0354,  ..., -0.0560, -0.0565,  0.0288],\n",
              "         [-0.3232, -1.2405,  0.5162,  ...,  0.3555,  0.3168, -0.5426],\n",
              "         [-0.0879, -0.9017,  0.3440,  ..., -0.4639,  0.3255, -0.3714],\n",
              "         ...,\n",
              "         [ 0.2597, -0.2686,  0.4233,  ..., -0.1625,  0.1485, -0.2570],\n",
              "         [ 0.2597, -0.2686,  0.4233,  ..., -0.1625,  0.1485, -0.2570],\n",
              "         [ 0.2597, -0.2686,  0.4233,  ..., -0.1625,  0.1485, -0.2570]],\n",
              "\n",
              "        [[-0.0243, -0.0833, -0.0354,  ..., -0.0520, -0.0573,  0.0236],\n",
              "         [-0.1936, -0.7430,  0.3936,  ..., -0.8061,  0.2341, -0.3885],\n",
              "         [ 0.1409, -0.1959,  0.0135,  ..., -0.6202,  0.1617, -0.1313],\n",
              "         ...,\n",
              "         [ 0.1109, -0.4761,  0.2166,  ..., -0.1445,  0.3955, -0.3169],\n",
              "         [ 0.1109, -0.4761,  0.2166,  ..., -0.1445,  0.3955, -0.3169],\n",
              "         [ 0.1109, -0.4761,  0.2166,  ..., -0.1445,  0.3955, -0.3169]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-0.0315, -0.0766, -0.0354,  ..., -0.0391, -0.0552,  0.0241],\n",
              "         [-0.4031, -0.1651,  0.6102,  ..., -0.0360,  0.7334, -0.1050],\n",
              "         [-0.0723, -0.9644,  0.4196,  ..., -0.3846,  0.5623, -0.2194],\n",
              "         ...,\n",
              "         [ 0.2142, -0.0516,  0.2992,  ..., -0.0626,  0.3703, -0.2578],\n",
              "         [ 0.2142, -0.0516,  0.2992,  ..., -0.0626,  0.3703, -0.2578],\n",
              "         [ 0.2142, -0.0516,  0.2992,  ..., -0.0626,  0.3703, -0.2578]],\n",
              "\n",
              "        [[-0.0386, -0.0755, -0.0336,  ..., -0.0582, -0.0572,  0.0337],\n",
              "         [-0.1415, -1.2191,  0.5056,  ...,  0.2314,  0.4492, -0.6575],\n",
              "         [ 0.1057,  1.0496,  0.2621,  ...,  0.2738,  0.4019, -0.5902],\n",
              "         ...,\n",
              "         [ 0.1260, -0.3112,  0.3055,  ..., -0.2072,  0.2737, -0.2621],\n",
              "         [ 0.1260, -0.3112,  0.3055,  ..., -0.2072,  0.2737, -0.2621],\n",
              "         [ 0.1260, -0.3112,  0.3055,  ..., -0.2072,  0.2737, -0.2621]],\n",
              "\n",
              "        [[-0.0330, -0.0834, -0.0272,  ..., -0.0663, -0.0622,  0.0254],\n",
              "         [-0.1787, -0.9540, -0.0228,  ...,  0.8019,  0.1597,  0.4084],\n",
              "         [-0.0798, -1.4259,  0.0669,  ..., -0.1433,  0.2219,  0.0752],\n",
              "         ...,\n",
              "         [ 0.0293,  0.1138, -0.0810,  ..., -0.0734,  0.0210,  0.0092],\n",
              "         [ 0.0277,  0.1127, -0.0733,  ..., -0.0712,  0.0144,  0.0130],\n",
              "         [ 0.2192, -0.2457, -0.0259,  ..., -0.1722, -0.0801, -0.1820]]],\n",
              "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 3.0064e-02, -6.0018e-02,  4.5163e-02,  ..., -7.1882e-02,\n",
              "          -9.8594e-03,  4.3513e-02],\n",
              "         [ 2.4582e-02, -5.8170e-01,  2.4277e-01,  ..., -8.3554e-01,\n",
              "           3.6373e-01, -6.8587e-02],\n",
              "         [ 6.9181e-02, -7.3208e-01, -1.5455e-01,  ..., -7.4906e-01,\n",
              "           3.0340e-01,  3.4862e-02],\n",
              "         ...,\n",
              "         [-8.6496e-05, -5.8227e-01, -6.4872e-02,  ...,  2.5374e-01,\n",
              "           2.4587e-01,  1.4160e-01],\n",
              "         [-8.6496e-05, -5.8227e-01, -6.4872e-02,  ...,  2.5374e-01,\n",
              "           2.4587e-01,  1.4160e-01],\n",
              "         [-8.6496e-05, -5.8227e-01, -6.4872e-02,  ...,  2.5374e-01,\n",
              "           2.4587e-01,  1.4160e-01]],\n",
              "\n",
              "        [[ 2.9824e-02, -5.6249e-02,  4.2752e-02,  ..., -7.0154e-02,\n",
              "          -9.3196e-03,  4.2061e-02],\n",
              "         [-1.8205e-01, -1.1986e+00,  4.0244e-01,  ...,  2.8757e-01,\n",
              "           2.1686e-01, -5.5736e-01],\n",
              "         [ 2.6527e-01, -7.8897e-01,  2.2677e-02,  ..., -6.1800e-01,\n",
              "           3.2683e-01, -2.5720e-01],\n",
              "         ...,\n",
              "         [ 1.8634e-01, -3.4228e-01,  3.9853e-02,  ...,  1.6431e-01,\n",
              "           9.7903e-02,  1.6509e-01],\n",
              "         [ 1.8634e-01, -3.4228e-01,  3.9853e-02,  ...,  1.6431e-01,\n",
              "           9.7903e-02,  1.6509e-01],\n",
              "         [ 1.8634e-01, -3.4228e-01,  3.9853e-02,  ...,  1.6431e-01,\n",
              "           9.7903e-02,  1.6509e-01]],\n",
              "\n",
              "        [[ 3.0821e-02, -5.5772e-02,  4.3649e-02,  ..., -7.1034e-02,\n",
              "          -7.1718e-03,  4.4100e-02],\n",
              "         [-1.4501e-02, -8.1252e-01,  2.1334e-01,  ..., -7.5687e-01,\n",
              "           2.1905e-01,  7.0794e-03],\n",
              "         [ 4.6747e-01, -1.2697e-01, -1.4156e-01,  ..., -7.3594e-01,\n",
              "           2.6459e-01, -2.4012e-02],\n",
              "         ...,\n",
              "         [ 9.8112e-03, -6.8144e-01, -1.7696e-02,  ...,  1.2205e-01,\n",
              "           2.3558e-01,  2.1702e-01],\n",
              "         [ 9.8112e-03, -6.8144e-01, -1.7696e-02,  ...,  1.2205e-01,\n",
              "           2.3558e-01,  2.1702e-01],\n",
              "         [ 9.8112e-03, -6.8144e-01, -1.7696e-02,  ...,  1.2205e-01,\n",
              "           2.3558e-01,  2.1702e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 2.6585e-02, -5.0697e-02,  4.2312e-02,  ..., -6.5213e-02,\n",
              "          -1.0529e-02,  3.9843e-02],\n",
              "         [-2.1815e-01, -2.1329e-01,  5.9823e-02,  ...,  8.3189e-02,\n",
              "           2.0244e-01, -4.7853e-02],\n",
              "         [ 3.6899e-02, -8.3954e-01,  2.5249e-01,  ..., -3.6920e-01,\n",
              "           2.8406e-01, -6.9481e-02],\n",
              "         ...,\n",
              "         [ 2.1883e-01, -1.0487e-01, -9.2181e-02,  ...,  3.4018e-01,\n",
              "           2.4322e-01,  1.3457e-01],\n",
              "         [ 2.1883e-01, -1.0487e-01, -9.2181e-02,  ...,  3.4018e-01,\n",
              "           2.4322e-01,  1.3457e-01],\n",
              "         [ 2.1883e-01, -1.0487e-01, -9.2181e-02,  ...,  3.4018e-01,\n",
              "           2.4322e-01,  1.3457e-01]],\n",
              "\n",
              "        [[ 2.7463e-02, -5.2855e-02,  4.7210e-02,  ..., -7.3938e-02,\n",
              "          -7.4207e-03,  4.7504e-02],\n",
              "         [-1.0528e-03, -1.0533e+00,  3.5597e-01,  ...,  1.3157e-01,\n",
              "           3.1652e-01, -5.4455e-01],\n",
              "         [-7.1504e-02,  5.7977e-01,  2.7069e-01,  ...,  1.6027e-01,\n",
              "           3.3210e-01, -4.6484e-01],\n",
              "         ...,\n",
              "         [ 1.2933e-01, -3.4717e-01,  3.9974e-03,  ...,  7.7679e-02,\n",
              "           1.5856e-01,  4.1693e-01],\n",
              "         [ 1.2933e-01, -3.4717e-01,  3.9974e-03,  ...,  7.7679e-02,\n",
              "           1.5856e-01,  4.1693e-01],\n",
              "         [ 1.2933e-01, -3.4717e-01,  3.9974e-03,  ...,  7.7679e-02,\n",
              "           1.5856e-01,  4.1693e-01]],\n",
              "\n",
              "        [[ 2.7947e-02, -5.7173e-02,  4.1827e-02,  ..., -7.4949e-02,\n",
              "          -9.5985e-03,  4.3305e-02],\n",
              "         [-1.2168e-01, -7.3291e-01, -2.3895e-01,  ...,  6.4755e-01,\n",
              "          -9.7799e-02,  2.2616e-01],\n",
              "         [-9.1779e-02, -1.0919e+00, -9.4288e-02,  ..., -3.2315e-01,\n",
              "           1.9419e-01,  3.6439e-03],\n",
              "         ...,\n",
              "         [ 1.0684e-02,  3.3646e-02,  2.4567e-02,  ...,  2.1810e-02,\n",
              "          -1.2737e-02, -2.8997e-02],\n",
              "         [ 8.4640e-03,  3.3383e-02,  2.4526e-02,  ...,  2.0367e-02,\n",
              "          -1.4506e-02, -3.0914e-02],\n",
              "         [ 2.5127e-01, -2.3936e-01, -2.4771e-01,  ...,  1.3283e-01,\n",
              "          -4.6253e-02,  4.3195e-01]]], device='cuda:0',\n",
              "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-1.1466e-02, -3.6746e-02,  1.9878e-01,  ..., -2.1735e-01,\n",
              "           3.3757e-02, -4.1047e-03],\n",
              "         [ 2.9636e-01, -5.3419e-01, -5.2510e-02,  ..., -7.5950e-01,\n",
              "           4.6796e-01,  3.0675e-01],\n",
              "         [-6.3510e-02, -8.1429e-01,  4.3600e-02,  ..., -7.9622e-01,\n",
              "           3.6193e-01,  5.7456e-01],\n",
              "         ...,\n",
              "         [ 1.9144e-02, -7.9707e-01, -2.4092e-01,  ..., -2.3913e-02,\n",
              "           3.3144e-01,  3.8798e-01],\n",
              "         [ 1.9144e-02, -7.9707e-01, -2.4092e-01,  ..., -2.3913e-02,\n",
              "           3.3144e-01,  3.8798e-01],\n",
              "         [ 1.9144e-02, -7.9707e-01, -2.4092e-01,  ..., -2.3913e-02,\n",
              "           3.3144e-01,  3.8798e-01]],\n",
              "\n",
              "        [[ 5.8817e-02, -5.6268e-02,  1.6320e-01,  ..., -2.2451e-01,\n",
              "          -7.1485e-03, -7.9313e-03],\n",
              "         [-4.2593e-01, -4.3738e-01,  1.2404e-01,  ...,  4.2738e-01,\n",
              "           4.1389e-01,  5.5123e-02],\n",
              "         [-2.3841e-02, -6.3685e-01,  1.3332e-01,  ..., -6.0542e-01,\n",
              "           1.2966e-01,  1.3704e-01],\n",
              "         ...,\n",
              "         [ 9.3723e-02, -7.0594e-01, -1.6052e-01,  ...,  1.0790e-01,\n",
              "           1.9730e-01,  2.9312e-01],\n",
              "         [ 9.3723e-02, -7.0594e-01, -1.6052e-01,  ...,  1.0790e-01,\n",
              "           1.9730e-01,  2.9312e-01],\n",
              "         [ 9.3723e-02, -7.0594e-01, -1.6052e-01,  ...,  1.0790e-01,\n",
              "           1.9730e-01,  2.9312e-01]],\n",
              "\n",
              "        [[ 2.5834e-04, -7.0329e-04,  1.5829e-01,  ..., -2.0491e-01,\n",
              "           3.5128e-02, -1.1613e-02],\n",
              "         [ 4.2842e-01, -7.8778e-01, -2.5135e-01,  ..., -6.6918e-01,\n",
              "           4.7872e-01,  2.9207e-01],\n",
              "         [ 1.9380e-01, -2.9929e-02,  3.2075e-02,  ..., -6.4783e-01,\n",
              "           4.7087e-01,  7.2787e-02],\n",
              "         ...,\n",
              "         [ 1.8233e-02, -7.6135e-01, -1.8551e-01,  ..., -1.3187e-01,\n",
              "           3.9540e-01,  5.0715e-01],\n",
              "         [ 1.8233e-02, -7.6135e-01, -1.8551e-01,  ..., -1.3187e-01,\n",
              "           3.9540e-01,  5.0715e-01],\n",
              "         [ 1.8233e-02, -7.6135e-01, -1.8551e-01,  ..., -1.3187e-01,\n",
              "           3.9540e-01,  5.0715e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 5.2179e-02, -3.3157e-02,  2.1536e-01,  ..., -2.0459e-01,\n",
              "          -1.2410e-02, -5.4045e-03],\n",
              "         [-1.8693e-01, -1.3914e-01, -7.5257e-02,  ...,  2.5702e-01,\n",
              "           1.9900e-01,  2.0310e-01],\n",
              "         [-7.2887e-02, -5.8143e-01,  2.3961e-01,  ..., -5.0906e-01,\n",
              "           3.2616e-01, -2.1285e-01],\n",
              "         ...,\n",
              "         [ 2.5658e-01, -4.3558e-01,  9.1566e-02,  ...,  1.3608e-01,\n",
              "           2.5872e-01,  3.6071e-01],\n",
              "         [ 2.5658e-01, -4.3558e-01,  9.1566e-02,  ...,  1.3608e-01,\n",
              "           2.5872e-01,  3.6071e-01],\n",
              "         [ 2.5658e-01, -4.3558e-01,  9.1566e-02,  ...,  1.3608e-01,\n",
              "           2.5872e-01,  3.6071e-01]],\n",
              "\n",
              "        [[ 4.0843e-02, -5.0530e-02,  2.1328e-01,  ..., -1.9383e-01,\n",
              "           1.5142e-02, -3.2906e-02],\n",
              "         [-2.7048e-01, -3.4828e-01,  3.3195e-01,  ...,  1.0709e-01,\n",
              "           4.3652e-01,  2.3025e-01],\n",
              "         [-6.2519e-02,  2.5417e-01,  2.1774e-01,  ...,  9.9514e-02,\n",
              "           3.1537e-01, -7.8198e-02],\n",
              "         ...,\n",
              "         [ 2.2252e-01, -7.6709e-01, -1.1532e-01,  ..., -1.8560e-01,\n",
              "           7.8981e-02,  5.3527e-01],\n",
              "         [ 2.2252e-01, -7.6709e-01, -1.1532e-01,  ..., -1.8560e-01,\n",
              "           7.8981e-02,  5.3527e-01],\n",
              "         [ 2.2252e-01, -7.6709e-01, -1.1532e-01,  ..., -1.8560e-01,\n",
              "           7.8981e-02,  5.3527e-01]],\n",
              "\n",
              "        [[ 1.3320e-02, -5.7118e-02,  1.7620e-01,  ..., -1.9971e-01,\n",
              "          -4.1401e-03, -9.5721e-03],\n",
              "         [-2.0846e-01, -5.4659e-01, -5.3439e-01,  ...,  4.6269e-01,\n",
              "           2.2729e-01,  5.5246e-01],\n",
              "         [-2.0283e-01, -7.6324e-01, -7.6097e-02,  ..., -5.7159e-01,\n",
              "           6.1425e-02,  3.5275e-01],\n",
              "         ...,\n",
              "         [ 1.4268e-02, -1.7627e-02,  1.8611e-01,  ..., -1.5523e-01,\n",
              "           2.2581e-02, -4.8839e-02],\n",
              "         [ 1.3065e-02, -1.6874e-02,  1.8173e-01,  ..., -1.5355e-01,\n",
              "           2.3228e-02, -5.0524e-02],\n",
              "         [ 2.9508e-01, -5.5983e-01, -2.0431e-01,  ..., -1.8913e-01,\n",
              "          -1.0397e-01,  5.7230e-01]]], device='cuda:0',\n",
              "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 9.1169e-02,  2.8473e-02, -6.8455e-02,  ..., -9.3672e-02,\n",
              "          -1.2067e-02,  4.3084e-02],\n",
              "         [ 3.6181e-01, -5.6317e-01, -1.7724e-01,  ..., -8.0733e-01,\n",
              "           2.3852e-01,  5.5303e-01],\n",
              "         [ 5.8375e-01, -7.1341e-01, -1.0683e-01,  ..., -8.0513e-01,\n",
              "           9.0226e-02,  3.7852e-01],\n",
              "         ...,\n",
              "         [ 1.0418e+00, -3.0926e-01, -8.7614e-01,  ..., -2.9145e-02,\n",
              "           1.4010e-01,  2.4322e-01],\n",
              "         [ 1.0418e+00, -3.0926e-01, -8.7614e-01,  ..., -2.9145e-02,\n",
              "           1.4010e-01,  2.4322e-01],\n",
              "         [ 1.0418e+00, -3.0926e-01, -8.7614e-01,  ..., -2.9145e-02,\n",
              "           1.4010e-01,  2.4322e-01]],\n",
              "\n",
              "        [[ 8.7513e-02,  1.8299e-02, -7.1046e-02,  ..., -8.4292e-02,\n",
              "           2.0743e-02,  6.6938e-03],\n",
              "         [ 4.3931e-01, -4.7247e-01,  1.7661e-01,  ...,  3.1768e-01,\n",
              "           3.2112e-01, -4.4102e-02],\n",
              "         [ 3.5205e-01, -3.6880e-01, -1.1054e-02,  ..., -8.3875e-01,\n",
              "           2.7534e-01,  2.0114e-01],\n",
              "         ...,\n",
              "         [ 1.0683e+00, -2.4215e-01, -7.4508e-01,  ...,  2.7985e-01,\n",
              "          -5.6599e-02, -6.8470e-02],\n",
              "         [ 1.0683e+00, -2.4215e-01, -7.4508e-01,  ...,  2.7985e-01,\n",
              "          -5.6599e-02, -6.8470e-02],\n",
              "         [ 1.0683e+00, -2.4215e-01, -7.4508e-01,  ...,  2.7985e-01,\n",
              "          -5.6599e-02, -6.8470e-02]],\n",
              "\n",
              "        [[ 2.9965e-02,  4.1829e-02, -5.3125e-02,  ..., -4.7855e-02,\n",
              "          -1.2310e-02,  3.1538e-02],\n",
              "         [ 5.0613e-01, -5.3181e-01, -2.3943e-01,  ..., -8.5205e-01,\n",
              "           3.5244e-01,  4.6307e-01],\n",
              "         [ 5.5777e-01,  5.3734e-02, -2.1571e-02,  ..., -8.3667e-01,\n",
              "           2.8749e-01,  1.6366e-01],\n",
              "         ...,\n",
              "         [ 8.2071e-01, -1.6571e-01, -7.6558e-01,  ...,  5.8856e-03,\n",
              "           2.2744e-01,  4.4577e-01],\n",
              "         [ 8.2071e-01, -1.6571e-01, -7.6558e-01,  ...,  5.8856e-03,\n",
              "           2.2744e-01,  4.4577e-01],\n",
              "         [ 8.2071e-01, -1.6571e-01, -7.6558e-01,  ...,  5.8856e-03,\n",
              "           2.2744e-01,  4.4577e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 6.6319e-02,  4.0392e-02, -1.6717e-02,  ..., -5.4453e-02,\n",
              "           3.8195e-02,  3.0986e-02],\n",
              "         [ 6.1819e-01, -2.3454e-01,  9.3272e-02,  ..., -1.0996e-01,\n",
              "          -7.4030e-02,  5.3079e-02],\n",
              "         [ 8.9194e-01, -3.8060e-01,  1.2338e-01,  ..., -7.8833e-01,\n",
              "           1.9288e-01, -1.9100e-01],\n",
              "         ...,\n",
              "         [ 1.2410e+00,  1.9849e-02, -4.4220e-01,  ...,  2.3444e-01,\n",
              "           6.3724e-02,  9.0144e-02],\n",
              "         [ 1.2410e+00,  1.9849e-02, -4.4220e-01,  ...,  2.3444e-01,\n",
              "           6.3724e-02,  9.0144e-02],\n",
              "         [ 1.2410e+00,  1.9849e-02, -4.4220e-01,  ...,  2.3444e-01,\n",
              "           6.3724e-02,  9.0144e-02]],\n",
              "\n",
              "        [[ 9.2402e-02,  3.6695e-02, -3.9440e-02,  ..., -5.0695e-02,\n",
              "          -3.3741e-02,  3.7678e-02],\n",
              "         [ 6.3924e-01, -3.4547e-01,  3.1620e-01,  ..., -6.3120e-02,\n",
              "           3.1656e-01,  1.1608e-01],\n",
              "         [ 6.0894e-01,  1.6980e-01, -1.1021e-01,  ..., -1.0839e-01,\n",
              "          -2.3059e-01, -1.5170e-01],\n",
              "         ...,\n",
              "         [ 9.0598e-01, -5.1439e-02, -9.3407e-01,  ...,  2.7488e-02,\n",
              "           1.7296e-02,  9.2480e-02],\n",
              "         [ 9.0598e-01, -5.1439e-02, -9.3407e-01,  ...,  2.7488e-02,\n",
              "           1.7296e-02,  9.2480e-02],\n",
              "         [ 9.0598e-01, -5.1439e-02, -9.3407e-01,  ...,  2.7488e-02,\n",
              "           1.7296e-02,  9.2480e-02]],\n",
              "\n",
              "        [[ 6.0469e-02,  6.0978e-02, -6.4458e-02,  ..., -7.4157e-02,\n",
              "          -3.0499e-02,  1.8133e-02],\n",
              "         [ 5.5946e-01, -1.5551e-01, -5.2362e-01,  ...,  1.8304e-01,\n",
              "           2.2459e-01,  1.6088e-01],\n",
              "         [ 7.3145e-01,  1.3313e-01, -4.9818e-01,  ..., -7.0135e-01,\n",
              "          -5.7500e-02,  7.4001e-01],\n",
              "         ...,\n",
              "         [ 1.8914e-02,  7.1552e-02, -4.2588e-02,  ..., -4.2898e-02,\n",
              "          -1.5041e-03, -7.0742e-04],\n",
              "         [ 1.9081e-02,  7.1087e-02, -4.3131e-02,  ..., -4.2336e-02,\n",
              "          -1.6474e-03, -8.4449e-04],\n",
              "         [ 1.0111e+00,  3.3185e-02, -8.8719e-01,  ...,  2.8261e-02,\n",
              "          -1.2038e-01,  3.1424e-01]]], device='cuda:0',\n",
              "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-2.9367e-02,  1.7888e-02,  1.3699e-01,  ..., -1.2264e-01,\n",
              "           6.5705e-03,  9.7089e-02],\n",
              "         [ 3.9685e-01, -3.8969e-01,  2.6062e-01,  ..., -8.7589e-01,\n",
              "           7.6533e-02,  7.7775e-01],\n",
              "         [ 4.6303e-01, -4.1967e-01,  2.3987e-02,  ..., -1.1007e+00,\n",
              "           1.1613e-02,  8.0986e-01],\n",
              "         ...,\n",
              "         [ 2.3838e-01, -1.7386e-01, -7.4929e-02,  ..., -3.4214e-01,\n",
              "           1.3019e-01,  8.1555e-01],\n",
              "         [ 2.3838e-01, -1.7386e-01, -7.4929e-02,  ..., -3.4214e-01,\n",
              "           1.3019e-01,  8.1555e-01],\n",
              "         [ 2.3838e-01, -1.7386e-01, -7.4929e-02,  ..., -3.4214e-01,\n",
              "           1.3019e-01,  8.1555e-01]],\n",
              "\n",
              "        [[-5.5859e-02,  2.6160e-02,  1.0690e-01,  ..., -1.0690e-01,\n",
              "           1.4521e-02,  4.2066e-02],\n",
              "         [ 5.3364e-01, -2.9620e-01,  4.0048e-01,  ..., -9.7145e-03,\n",
              "           1.6451e-01,  4.5368e-02],\n",
              "         [ 2.9609e-01,  2.3294e-01,  3.2344e-01,  ..., -1.2516e+00,\n",
              "           9.7791e-02,  4.6418e-01],\n",
              "         ...,\n",
              "         [ 1.2626e-01, -1.0716e-01, -9.0861e-02,  ..., -1.3733e-01,\n",
              "          -3.1510e-02,  3.7181e-01],\n",
              "         [ 1.2626e-01, -1.0716e-01, -9.0861e-02,  ..., -1.3733e-01,\n",
              "          -3.1510e-02,  3.7181e-01],\n",
              "         [ 1.2626e-01, -1.0716e-01, -9.0861e-02,  ..., -1.3733e-01,\n",
              "          -3.1510e-02,  3.7181e-01]],\n",
              "\n",
              "        [[-3.0083e-02, -2.9017e-02,  1.1405e-01,  ..., -1.0812e-01,\n",
              "          -2.0152e-02,  8.0077e-02],\n",
              "         [ 4.8442e-01, -1.9638e-01,  5.4536e-01,  ..., -8.4070e-01,\n",
              "          -5.5636e-02,  6.4078e-01],\n",
              "         [ 5.5498e-01,  3.1023e-01,  2.2905e-01,  ..., -9.6354e-01,\n",
              "           3.7627e-03,  5.3429e-01],\n",
              "         ...,\n",
              "         [ 9.0728e-02,  3.1715e-02,  7.1658e-02,  ..., -2.9022e-01,\n",
              "           4.1347e-02,  7.2622e-01],\n",
              "         [ 9.0728e-02,  3.1715e-02,  7.1658e-02,  ..., -2.9022e-01,\n",
              "           4.1347e-02,  7.2622e-01],\n",
              "         [ 9.0728e-02,  3.1715e-02,  7.1658e-02,  ..., -2.9022e-01,\n",
              "           4.1347e-02,  7.2622e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-3.5902e-02,  1.7005e-02,  1.0923e-01,  ..., -1.3939e-01,\n",
              "           2.6437e-03,  1.0151e-01],\n",
              "         [ 5.7745e-01, -1.2255e-01,  3.4821e-01,  ..., -2.5878e-01,\n",
              "          -9.5528e-02,  3.5264e-01],\n",
              "         [ 3.8061e-01, -1.3611e-01,  4.7403e-02,  ..., -8.8379e-01,\n",
              "           6.8595e-04,  3.0070e-01],\n",
              "         ...,\n",
              "         [ 2.9835e-01, -1.1137e-01, -1.5013e-01,  ..., -1.4505e-01,\n",
              "          -2.6869e-01,  4.6438e-01],\n",
              "         [ 2.9835e-01, -1.1137e-01, -1.5013e-01,  ..., -1.4505e-01,\n",
              "          -2.6869e-01,  4.6438e-01],\n",
              "         [ 2.9835e-01, -1.1137e-01, -1.5013e-01,  ..., -1.4505e-01,\n",
              "          -2.6869e-01,  4.6438e-01]],\n",
              "\n",
              "        [[-6.8923e-03,  2.0153e-03,  1.1789e-01,  ..., -9.1055e-02,\n",
              "          -5.6450e-02,  1.0634e-01],\n",
              "         [ 7.3001e-01, -9.2953e-02,  8.8028e-01,  ..., -2.0517e-01,\n",
              "           2.4751e-01,  1.7620e-01],\n",
              "         [ 2.3443e-01,  5.3686e-01,  2.5081e-01,  ...,  6.1345e-02,\n",
              "          -3.7877e-02,  1.5508e-01],\n",
              "         ...,\n",
              "         [ 2.9979e-01,  2.0003e-01, -1.9961e-02,  ..., -1.7775e-01,\n",
              "          -1.1324e-03,  3.5621e-01],\n",
              "         [ 2.9979e-01,  2.0003e-01, -1.9961e-02,  ..., -1.7775e-01,\n",
              "          -1.1324e-03,  3.5621e-01],\n",
              "         [ 2.9979e-01,  2.0003e-01, -1.9961e-02,  ..., -1.7775e-01,\n",
              "          -1.1324e-03,  3.5621e-01]],\n",
              "\n",
              "        [[-1.4087e-02,  3.7753e-04,  9.4593e-02,  ..., -1.0565e-01,\n",
              "          -7.8990e-02,  1.0593e-01],\n",
              "         [ 1.5694e-01,  7.7701e-02,  4.1195e-01,  ...,  1.4045e-01,\n",
              "           1.9095e-01,  2.8250e-01],\n",
              "         [ 4.6137e-01,  4.1032e-01,  2.0415e-01,  ..., -7.7816e-01,\n",
              "          -6.5101e-02,  6.9472e-01],\n",
              "         ...,\n",
              "         [-3.0342e-02,  4.0592e-03,  1.0746e-01,  ..., -1.0348e-01,\n",
              "          -7.5917e-02,  9.2825e-02],\n",
              "         [-3.0384e-02,  3.7974e-03,  1.0768e-01,  ..., -1.0271e-01,\n",
              "          -7.5839e-02,  9.2585e-02],\n",
              "         [ 2.2049e-01,  1.3917e-01, -6.3272e-02,  ..., -1.9436e-01,\n",
              "          -5.8450e-02,  6.6395e-01]]], device='cuda:0',\n",
              "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.2088, -0.6811, -0.1561,  ..., -1.1462, -0.1140, -0.2448],\n",
              "         [ 0.5290, -0.6635, -0.6990,  ..., -0.7732, -0.2913,  0.0390],\n",
              "         [ 0.2166, -0.6995, -0.1378,  ..., -1.8138, -0.1516, -0.1556],\n",
              "         ...,\n",
              "         [ 0.1630, -0.3259, -0.0551,  ..., -1.0345, -0.1677,  0.0541],\n",
              "         [ 0.1630, -0.3259, -0.0551,  ..., -1.0345, -0.1677,  0.0541],\n",
              "         [ 0.1630, -0.3259, -0.0551,  ..., -1.0345, -0.1677,  0.0541]],\n",
              "\n",
              "        [[-0.2505, -0.5507, -0.2250,  ..., -0.9843, -0.1559, -0.6698],\n",
              "         [ 0.6746, -0.2041, -0.3255,  ..., -0.2904, -0.5190, -0.8475],\n",
              "         [ 0.4872, -0.4763, -0.0105,  ..., -1.7748, -0.1546, -0.4041],\n",
              "         ...,\n",
              "         [ 0.1681, -0.1697, -0.1721,  ..., -1.0247, -0.3770, -0.6031],\n",
              "         [ 0.1681, -0.1697, -0.1721,  ..., -1.0247, -0.3770, -0.6031],\n",
              "         [ 0.1681, -0.1697, -0.1721,  ..., -1.0247, -0.3770, -0.6031]],\n",
              "\n",
              "        [[-0.2991, -0.5298, -0.0963,  ..., -1.0094, -0.1061, -0.1816],\n",
              "         [ 0.4052, -0.4790, -0.4436,  ..., -0.4876, -0.3022,  0.0939],\n",
              "         [ 0.3204, -0.2422, -0.1232,  ..., -1.0488, -0.0584, -0.1989],\n",
              "         ...,\n",
              "         [-0.0851, -0.2211, -0.0804,  ..., -0.8629, -0.0579,  0.1882],\n",
              "         [-0.0851, -0.2211, -0.0804,  ..., -0.8629, -0.0579,  0.1882],\n",
              "         [-0.0851, -0.2211, -0.0804,  ..., -0.8629, -0.0579,  0.1882]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-0.1901, -0.5268, -0.0693,  ..., -1.0250, -0.1433, -0.3007],\n",
              "         [ 0.2914, -0.4207, -0.2049,  ..., -0.5977, -0.3587, -0.1991],\n",
              "         [ 0.4636, -0.4125, -0.3030,  ..., -1.5182, -0.0450, -0.0104],\n",
              "         ...,\n",
              "         [ 0.3026, -0.2267, -0.1560,  ..., -1.1202, -0.4249, -0.2683],\n",
              "         [ 0.3026, -0.2267, -0.1560,  ..., -1.1202, -0.4249, -0.2683],\n",
              "         [ 0.3026, -0.2267, -0.1560,  ..., -1.1202, -0.4249, -0.2683]],\n",
              "\n",
              "        [[-0.1078, -0.4296, -0.0499,  ..., -0.6516, -0.1223, -0.2892],\n",
              "         [ 0.6343, -0.0976, -0.0062,  ..., -0.1097, -0.3717, -0.3924],\n",
              "         [ 0.3723,  0.0790,  0.0040,  ..., -0.3200, -0.1021, -0.1479],\n",
              "         ...,\n",
              "         [ 0.1187, -0.2410, -0.0455,  ..., -0.5742, -0.2979, -0.3122],\n",
              "         [ 0.1187, -0.2410, -0.0455,  ..., -0.5742, -0.2979, -0.3122],\n",
              "         [ 0.1187, -0.2410, -0.0455,  ..., -0.5742, -0.2979, -0.3122]],\n",
              "\n",
              "        [[-0.3398, -0.5574, -0.1643,  ..., -0.7412, -0.0752, -0.3834],\n",
              "         [ 0.4769, -0.3704, -0.1341,  ..., -0.2497, -0.1212, -0.0272],\n",
              "         [ 0.4200, -0.3446,  0.0077,  ..., -0.9000, -0.3156,  0.3280],\n",
              "         ...,\n",
              "         [-0.3487, -0.5584, -0.1598,  ..., -0.7435, -0.0815, -0.3969],\n",
              "         [-0.3489, -0.5585, -0.1596,  ..., -0.7430, -0.0815, -0.3965],\n",
              "         [-0.0607, -0.3483, -0.0841,  ..., -0.6946, -0.3187, -0.1200]]],\n",
              "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)), attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "uejqQuIfktj_"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "nLsiC2emlCjS"
      },
      "outputs": [],
      "source": [
        "from transformers import get_scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "y8MKbw2RlMKt"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "3_1yr5KxlR1f"
      },
      "outputs": [],
      "source": [
        "loss_fct = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"[^a-zA-Z0-9áéíóúçãõâêô.,!? ]\", \"\", text)  # Remove caracteres especiais\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Remove múltiplos espaços\n",
        "    return text\n",
        "\n",
        "df['text'] = df['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "UmXQxeLlPwaO"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    lepochs = []\n",
        "    for batch, y in dl_train:\n",
        "        batch = {k: v.to(device) if hasattr(v, 'to') else v for k, v in batch.items()}\n",
        "        y = y.to(device)\n",
        "\n",
        "        outputs = model(**batch)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        loss = loss_fct(logits, y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        lepochs.append(loss.cpu().item())\n",
        "\n",
        "    print(f\"Época {epoch + 1}, perda média: {np.mean(lepochs):.4f}\")\n"
      ],
      "metadata": {
        "id": "qYK4UeChVOJS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d4733a-08b4-4bc9-df62-e98d7f1c3fa4"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 1, perda média: 0.7110\n",
            "Época 2, perda média: 0.6201\n",
            "Época 3, perda média: 0.4821\n",
            "Época 4, perda média: 0.3869\n",
            "Época 5, perda média: 0.2938\n",
            "Época 6, perda média: 0.2245\n",
            "Época 7, perda média: 0.1859\n",
            "Época 8, perda média: 0.1773\n",
            "Época 9, perda média: 0.2366\n",
            "Época 10, perda média: 0.1688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "CyWQ0fW3lvx0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ffda3eb-be6e-401e-e6f6-55702225e2ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "Rv3FsDAZlOCO"
      },
      "outputs": [],
      "source": [
        "ytrue = []\n",
        "ypred = []\n",
        "for batch,y in dl_eval:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "    ytrue += y.tolist()\n",
        "    ypred += predictions.cpu().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "CfeGCTJhIYjW"
      },
      "outputs": [],
      "source": [
        "x,y = next(iter(dl_eval))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "dtQtkWunIfC7"
      },
      "outputs": [],
      "source": [
        "batch = {k: v.to(device) for k, v in x.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "AM14wFfkIO4c"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(**batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "CRLwLzGEjlh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0615c8f-259a-4d6d-8902-0277df969581"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput(loss=None, logits=tensor([[-1.5037,  3.6773, -2.3219],\n",
              "        [ 3.0541, -1.7579, -1.0852],\n",
              "        [-1.4416, -3.2208,  4.5168],\n",
              "        [-0.8708, -3.4450,  4.2648],\n",
              "        [ 2.4519, -2.4167,  0.2550],\n",
              "        [-1.4090,  3.6190, -2.3232],\n",
              "        [-1.3426,  3.5330, -2.2896],\n",
              "        [ 3.0510, -1.8677, -0.9485]], device='cuda:0'), hidden_states=(tensor([[[ 0.1367, -0.0655, -0.0026,  ..., -0.0469,  0.0793,  0.0470],\n",
              "         [ 0.3979,  0.1129,  0.4660,  ..., -0.2251, -0.3789, -0.0552],\n",
              "         [-0.4929, -0.0110,  0.0886,  ..., -0.4282, -0.3098, -0.2146],\n",
              "         ...,\n",
              "         [-0.5148,  0.5250,  0.0034,  ..., -0.4045,  0.3282, -0.3598],\n",
              "         [-0.5148,  0.5250,  0.0034,  ..., -0.4045,  0.3282, -0.3598],\n",
              "         [-0.5148,  0.5250,  0.0034,  ..., -0.4045,  0.3282, -0.3598]],\n",
              "\n",
              "        [[ 0.1367, -0.0655, -0.0026,  ..., -0.0469,  0.0793,  0.0470],\n",
              "         [ 0.3979,  0.1129,  0.4660,  ..., -0.2251, -0.3789, -0.0552],\n",
              "         [-0.0331,  0.6154, -0.4321,  ...,  0.2614,  0.0904,  0.4262],\n",
              "         ...,\n",
              "         [-0.5148,  0.5250,  0.0034,  ..., -0.4045,  0.3282, -0.3598],\n",
              "         [-0.5148,  0.5250,  0.0034,  ..., -0.4045,  0.3282, -0.3598],\n",
              "         [-0.5148,  0.5250,  0.0034,  ..., -0.4045,  0.3282, -0.3598]],\n",
              "\n",
              "        [[ 0.1367, -0.0655, -0.0026,  ..., -0.0469,  0.0793,  0.0470],\n",
              "         [ 0.3979,  0.1129,  0.4660,  ..., -0.2251, -0.3789, -0.0552],\n",
              "         [-0.3457, -0.0815,  0.1458,  ..., -0.3683, -0.1481,  0.1844],\n",
              "         ...,\n",
              "         [-0.5148,  0.5250,  0.0034,  ..., -0.4045,  0.3282, -0.3598],\n",
              "         [-0.5148,  0.5250,  0.0034,  ..., -0.4045,  0.3282, -0.3598],\n",
              "         [-0.5148,  0.5250,  0.0034,  ..., -0.4045,  0.3282, -0.3598]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.1367, -0.0655, -0.0026,  ..., -0.0469,  0.0793,  0.0470],\n",
              "         [ 0.3979,  0.1129,  0.4660,  ..., -0.2251, -0.3789, -0.0552],\n",
              "         [-0.2819, -0.1389, -0.0040,  ...,  0.1288, -0.1860,  0.5264],\n",
              "         ...,\n",
              "         [-0.5148,  0.5250,  0.0034,  ..., -0.4045,  0.3282, -0.3598],\n",
              "         [-0.5148,  0.5250,  0.0034,  ..., -0.4045,  0.3282, -0.3598],\n",
              "         [-0.5148,  0.5250,  0.0034,  ..., -0.4045,  0.3282, -0.3598]],\n",
              "\n",
              "        [[ 0.1367, -0.0655, -0.0026,  ..., -0.0469,  0.0793,  0.0470],\n",
              "         [ 0.0372,  0.2764,  0.2144,  ...,  0.2227,  0.0679,  0.3851],\n",
              "         [ 0.1046,  0.4707, -0.3400,  ..., -0.1372, -0.0785,  0.4235],\n",
              "         ...,\n",
              "         [-0.5148,  0.5250,  0.0034,  ..., -0.4045,  0.3282, -0.3598],\n",
              "         [-0.5148,  0.5250,  0.0034,  ..., -0.4045,  0.3282, -0.3598],\n",
              "         [-0.5148,  0.5250,  0.0034,  ..., -0.4045,  0.3282, -0.3598]],\n",
              "\n",
              "        [[ 0.1367, -0.0655, -0.0026,  ..., -0.0469,  0.0793,  0.0470],\n",
              "         [ 0.0284,  0.2495,  0.2810,  ..., -0.3806, -0.0987, -0.1604],\n",
              "         [-0.3051,  0.3911, -0.0436,  ..., -0.3144, -0.3289,  0.4045],\n",
              "         ...,\n",
              "         [-0.5148,  0.5250,  0.0034,  ..., -0.4045,  0.3282, -0.3598],\n",
              "         [-0.5148,  0.5250,  0.0034,  ..., -0.4045,  0.3282, -0.3598],\n",
              "         [-0.5148,  0.5250,  0.0034,  ..., -0.4045,  0.3282, -0.3598]]],\n",
              "       device='cuda:0'), tensor([[[ 2.1704e-02,  3.5434e-02,  9.6900e-03,  ..., -3.9716e-02,\n",
              "           3.3419e-02,  3.7730e-03],\n",
              "         [ 3.1807e-01, -9.3587e-02,  9.8816e-01,  ..., -3.4782e-02,\n",
              "          -1.4538e-02, -3.9006e-01],\n",
              "         [-5.1157e-01,  4.4174e-01, -3.0516e-01,  ..., -9.5236e-01,\n",
              "          -8.0326e-01, -5.9052e-01],\n",
              "         ...,\n",
              "         [ 5.2895e-02,  2.6578e-01,  2.9851e-01,  ..., -2.4252e-01,\n",
              "          -2.0845e-01,  1.9461e-01],\n",
              "         [ 5.2895e-02,  2.6578e-01,  2.9851e-01,  ..., -2.4252e-01,\n",
              "          -2.0845e-01,  1.9461e-01],\n",
              "         [ 5.2895e-02,  2.6578e-01,  2.9851e-01,  ..., -2.4252e-01,\n",
              "          -2.0845e-01,  1.9461e-01]],\n",
              "\n",
              "        [[ 7.9212e-03,  8.5287e-02, -4.2547e-04,  ..., -2.4957e-02,\n",
              "           5.5825e-02,  9.6684e-03],\n",
              "         [ 2.9482e-01, -1.5721e-01,  9.2444e-01,  ..., -3.9952e-02,\n",
              "           1.5990e-01, -3.1350e-01],\n",
              "         [-3.0550e-04,  1.7559e+00, -9.9506e-01,  ...,  4.9655e-01,\n",
              "           1.8313e-01,  3.3630e-01],\n",
              "         ...,\n",
              "         [-1.0568e-01,  5.7232e-01,  3.1700e-02,  ..., -5.8262e-01,\n",
              "          -2.1345e-01,  6.9107e-02],\n",
              "         [-1.0568e-01,  5.7232e-01,  3.1700e-02,  ..., -5.8262e-01,\n",
              "          -2.1345e-01,  6.9107e-02],\n",
              "         [-1.0568e-01,  5.7232e-01,  3.1700e-02,  ..., -5.8262e-01,\n",
              "          -2.1345e-01,  6.9107e-02]],\n",
              "\n",
              "        [[ 2.8955e-02,  3.7153e-02,  1.7477e-02,  ..., -6.2505e-02,\n",
              "           1.9858e-02,  5.6157e-03],\n",
              "         [ 3.0787e-01, -1.6789e-02,  9.6856e-01,  ..., -3.4392e-01,\n",
              "          -6.7245e-02, -4.3208e-01],\n",
              "         [-1.0393e-01,  1.2781e-01,  2.3034e-01,  ..., -6.1007e-01,\n",
              "          -1.4030e-01, -2.0353e-01],\n",
              "         ...,\n",
              "         [ 8.0747e-02,  2.6144e-01,  3.3266e-01,  ..., -2.4092e-01,\n",
              "          -2.2117e-01,  8.4137e-02],\n",
              "         [ 8.0747e-02,  2.6144e-01,  3.3266e-01,  ..., -2.4092e-01,\n",
              "          -2.2117e-01,  8.4137e-02],\n",
              "         [ 8.0747e-02,  2.6144e-01,  3.3266e-01,  ..., -2.4092e-01,\n",
              "          -2.2117e-01,  8.4137e-02]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 9.9914e-03,  4.4207e-02,  1.0341e-02,  ..., -4.8269e-02,\n",
              "           3.4817e-02,  2.3012e-02],\n",
              "         [ 2.7811e-01,  1.3301e-01,  9.0669e-01,  ..., -2.2284e-01,\n",
              "          -5.3390e-03, -7.7609e-02],\n",
              "         [-6.5176e-01, -2.8614e-01, -1.1494e-02,  ...,  2.0199e-01,\n",
              "          -2.8237e-01,  5.9209e-01],\n",
              "         ...,\n",
              "         [-6.6694e-04,  3.0778e-01,  3.1231e-01,  ..., -2.7560e-01,\n",
              "          -2.2601e-01,  2.0361e-01],\n",
              "         [-6.6694e-04,  3.0778e-01,  3.1231e-01,  ..., -2.7560e-01,\n",
              "          -2.2601e-01,  2.0361e-01],\n",
              "         [-6.6694e-04,  3.0778e-01,  3.1231e-01,  ..., -2.7560e-01,\n",
              "          -2.2601e-01,  2.0361e-01]],\n",
              "\n",
              "        [[ 1.8708e-02,  3.5023e-02,  1.6629e-02,  ..., -6.6133e-02,\n",
              "           2.9370e-02,  1.6394e-03],\n",
              "         [-2.5455e-01,  5.9476e-01,  2.0992e-01,  ..., -2.6884e-01,\n",
              "          -3.4581e-02,  6.5203e-01],\n",
              "         [ 4.4594e-01,  1.2020e+00, -4.1954e-01,  ..., -5.0437e-01,\n",
              "          -5.9645e-02,  5.4801e-01],\n",
              "         ...,\n",
              "         [-1.2369e-02,  3.3303e-01,  3.4068e-01,  ..., -2.7004e-01,\n",
              "          -1.4763e-01,  2.0417e-01],\n",
              "         [-1.2369e-02,  3.3303e-01,  3.4068e-01,  ..., -2.7004e-01,\n",
              "          -1.4763e-01,  2.0417e-01],\n",
              "         [-1.2369e-02,  3.3303e-01,  3.4068e-01,  ..., -2.7004e-01,\n",
              "          -1.4763e-01,  2.0417e-01]],\n",
              "\n",
              "        [[ 1.4379e-02,  7.6626e-02,  1.5799e-03,  ..., -5.7741e-02,\n",
              "           5.4175e-02, -1.2901e-03],\n",
              "         [-1.0583e-01,  5.0461e-01,  3.9558e-01,  ..., -9.3068e-01,\n",
              "           2.8824e-01, -5.9881e-01],\n",
              "         [-4.0374e-01,  9.1079e-01, -1.9736e-01,  ..., -8.5920e-01,\n",
              "          -3.1376e-01,  7.0160e-01],\n",
              "         ...,\n",
              "         [-2.1277e-02,  5.7690e-01,  1.5144e-02,  ..., -3.6129e-01,\n",
              "          -3.2760e-02,  1.1398e-01],\n",
              "         [-2.1277e-02,  5.7690e-01,  1.5144e-02,  ..., -3.6129e-01,\n",
              "          -3.2760e-02,  1.1398e-01],\n",
              "         [-2.1277e-02,  5.7690e-01,  1.5144e-02,  ..., -3.6129e-01,\n",
              "          -3.2760e-02,  1.1398e-01]]], device='cuda:0'), tensor([[[ 0.0129,  0.0461,  0.0276,  ..., -0.0752,  0.0574,  0.0250],\n",
              "         [ 0.0148, -0.5404,  1.0189,  ...,  0.0392,  0.5987,  0.7178],\n",
              "         [-0.2497,  0.9625, -0.2718,  ..., -1.4232, -0.6360,  0.2321],\n",
              "         ...,\n",
              "         [-0.3019,  0.2624, -0.1876,  ..., -0.0981,  0.0699, -0.0453],\n",
              "         [-0.3019,  0.2624, -0.1876,  ..., -0.0981,  0.0699, -0.0453],\n",
              "         [-0.3019,  0.2624, -0.1876,  ..., -0.0981,  0.0699, -0.0453]],\n",
              "\n",
              "        [[ 0.0189,  0.0542,  0.0248,  ..., -0.0702,  0.0540,  0.0186],\n",
              "         [-0.1026, -0.6454,  0.8460,  ..., -0.1848,  0.6993,  0.8741],\n",
              "         [-0.1226,  2.2171, -0.5811,  ...,  0.1244, -0.0172,  0.0659],\n",
              "         ...,\n",
              "         [-0.2683,  0.6335, -0.2226,  ...,  0.0087, -0.1462, -0.2180],\n",
              "         [-0.2683,  0.6335, -0.2226,  ...,  0.0087, -0.1462, -0.2180],\n",
              "         [-0.2683,  0.6335, -0.2226,  ...,  0.0087, -0.1462, -0.2180]],\n",
              "\n",
              "        [[ 0.0177,  0.0448,  0.0306,  ..., -0.0785,  0.0482,  0.0195],\n",
              "         [-0.1421, -0.4660,  1.0450,  ..., -0.0524,  0.7785,  0.4321],\n",
              "         [-0.2198,  0.4942,  0.4787,  ..., -0.4792,  0.6200,  0.0273],\n",
              "         ...,\n",
              "         [-0.4839,  0.1259, -0.2323,  ..., -0.2714,  0.5212, -0.2501],\n",
              "         [-0.4839,  0.1259, -0.2323,  ..., -0.2714,  0.5212, -0.2501],\n",
              "         [-0.4839,  0.1259, -0.2323,  ..., -0.2714,  0.5212, -0.2501]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.0210,  0.0490,  0.0285,  ..., -0.0716,  0.0564,  0.0288],\n",
              "         [ 0.0378, -0.2371,  0.8888,  ..., -0.2992,  0.7301,  0.6935],\n",
              "         [-0.6282, -0.5374,  0.2364,  ..., -0.0033, -0.6491,  0.4581],\n",
              "         ...,\n",
              "         [-0.2485,  0.3170, -0.0117,  ...,  0.0381,  0.0181,  0.0572],\n",
              "         [-0.2485,  0.3170, -0.0117,  ...,  0.0381,  0.0181,  0.0572],\n",
              "         [-0.2485,  0.3170, -0.0117,  ...,  0.0381,  0.0181,  0.0572]],\n",
              "\n",
              "        [[ 0.0119,  0.0429,  0.0332,  ..., -0.0827,  0.0521,  0.0244],\n",
              "         [ 0.0036,  0.7704,  0.0394,  ..., -0.4251,  0.4767,  0.7890],\n",
              "         [-0.7871,  1.1745, -0.2112,  ..., -1.3801,  0.4208,  0.2061],\n",
              "         ...,\n",
              "         [-0.1722,  0.6640, -0.0033,  ...,  0.1111,  0.6282,  0.1821],\n",
              "         [-0.1722,  0.6640, -0.0033,  ...,  0.1111,  0.6282,  0.1821],\n",
              "         [-0.1722,  0.6640, -0.0033,  ...,  0.1111,  0.6282,  0.1821]],\n",
              "\n",
              "        [[ 0.0224,  0.0480,  0.0280,  ..., -0.0778,  0.0545,  0.0146],\n",
              "         [ 0.3223,  0.7847,  0.0729,  ..., -1.2678,  0.3632, -0.1529],\n",
              "         [-0.0773,  1.1898, -0.3396,  ..., -1.1046, -0.0164,  0.8291],\n",
              "         ...,\n",
              "         [-0.2306,  0.5104, -0.1826,  ...,  0.0520, -0.0633, -0.1608],\n",
              "         [-0.2306,  0.5104, -0.1826,  ...,  0.0520, -0.0633, -0.1608],\n",
              "         [-0.2306,  0.5104, -0.1826,  ...,  0.0520, -0.0633, -0.1608]]],\n",
              "       device='cuda:0'), tensor([[[-1.3204e-01,  1.2309e-01,  9.9030e-02,  ...,  6.8961e-02,\n",
              "          -4.2548e-02,  1.1213e-01],\n",
              "         [ 7.5075e-02, -5.0377e-01,  1.2260e-01,  ...,  5.0699e-01,\n",
              "           3.3805e-01,  6.6545e-01],\n",
              "         [-5.7727e-01,  6.1469e-01, -2.2602e-02,  ..., -1.5695e+00,\n",
              "          -9.3816e-01,  4.0383e-01],\n",
              "         ...,\n",
              "         [-4.2404e-01,  2.3483e-01, -5.0835e-01,  ..., -3.3607e-03,\n",
              "           4.7640e-01,  4.0946e-01],\n",
              "         [-4.2404e-01,  2.3483e-01, -5.0835e-01,  ..., -3.3607e-03,\n",
              "           4.7640e-01,  4.0946e-01],\n",
              "         [-4.2404e-01,  2.3483e-01, -5.0835e-01,  ..., -3.3607e-03,\n",
              "           4.7640e-01,  4.0946e-01]],\n",
              "\n",
              "        [[-1.1647e-01,  1.1796e-01,  1.0621e-01,  ...,  7.2272e-02,\n",
              "          -1.3633e-02,  1.1387e-01],\n",
              "         [-3.5094e-01, -4.1348e-01, -4.9476e-02,  ...,  3.2572e-01,\n",
              "           5.4707e-01,  8.2142e-01],\n",
              "         [-1.3524e-01,  1.9127e+00,  1.1685e-01,  ...,  1.4923e-01,\n",
              "           1.1038e-02,  2.2084e-01],\n",
              "         ...,\n",
              "         [-4.6484e-01,  4.8341e-02, -3.8362e-01,  ...,  2.0213e-01,\n",
              "           4.6192e-01,  3.9995e-01],\n",
              "         [-4.6484e-01,  4.8341e-02, -3.8362e-01,  ...,  2.0213e-01,\n",
              "           4.6192e-01,  3.9995e-01],\n",
              "         [-4.6484e-01,  4.8341e-02, -3.8362e-01,  ...,  2.0213e-01,\n",
              "           4.6192e-01,  3.9995e-01]],\n",
              "\n",
              "        [[-1.3475e-01,  1.2082e-01,  1.1070e-01,  ...,  8.1225e-02,\n",
              "          -4.6473e-02,  1.0259e-01],\n",
              "         [ 3.4258e-02, -4.4057e-01, -9.7354e-02,  ...,  5.5924e-01,\n",
              "           1.2083e-01,  3.1303e-01],\n",
              "         [-2.0139e-01,  5.7827e-01,  3.9743e-01,  ..., -2.6830e-01,\n",
              "           2.0767e-01,  5.9660e-03],\n",
              "         ...,\n",
              "         [-4.9157e-01, -2.3068e-03, -3.0984e-01,  ...,  1.9701e-02,\n",
              "           5.4865e-01,  1.4633e-01],\n",
              "         [-4.9157e-01, -2.3068e-03, -3.0984e-01,  ...,  1.9701e-02,\n",
              "           5.4865e-01,  1.4633e-01],\n",
              "         [-4.9157e-01, -2.3068e-03, -3.0984e-01,  ...,  1.9701e-02,\n",
              "           5.4865e-01,  1.4633e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.3017e-01,  1.1800e-01,  1.0468e-01,  ...,  7.1376e-02,\n",
              "          -4.4005e-02,  1.0774e-01],\n",
              "         [ 1.3590e-01, -1.0139e-01, -7.6862e-02,  ...,  3.6160e-01,\n",
              "           2.6615e-01,  5.8992e-01],\n",
              "         [-1.3984e-02, -5.7104e-01,  2.2893e-01,  ..., -3.9940e-01,\n",
              "          -2.0368e-01,  2.7524e-01],\n",
              "         ...,\n",
              "         [-4.0556e-01,  1.5202e-01, -5.0104e-01,  ...,  1.9033e-01,\n",
              "           5.2437e-01,  3.4515e-01],\n",
              "         [-4.0556e-01,  1.5202e-01, -5.0104e-01,  ...,  1.9033e-01,\n",
              "           5.2437e-01,  3.4515e-01],\n",
              "         [-4.0556e-01,  1.5202e-01, -5.0104e-01,  ...,  1.9033e-01,\n",
              "           5.2437e-01,  3.4515e-01]],\n",
              "\n",
              "        [[-1.4113e-01,  1.1105e-01,  1.0482e-01,  ...,  7.4632e-02,\n",
              "          -4.5268e-02,  1.0831e-01],\n",
              "         [ 2.4465e-01,  8.6615e-01, -1.7717e-01,  ..., -5.1673e-01,\n",
              "           5.3781e-02,  8.2071e-01],\n",
              "         [-6.0417e-01,  6.2532e-01, -6.9352e-01,  ..., -1.2881e+00,\n",
              "          -2.2689e-01,  1.0603e-01],\n",
              "         ...,\n",
              "         [-4.8636e-01,  1.7993e-01, -3.2960e-01,  ...,  3.8114e-01,\n",
              "           6.4153e-01,  3.8159e-01],\n",
              "         [-4.8636e-01,  1.7993e-01, -3.2960e-01,  ...,  3.8114e-01,\n",
              "           6.4153e-01,  3.8159e-01],\n",
              "         [-4.8636e-01,  1.7993e-01, -3.2960e-01,  ...,  3.8114e-01,\n",
              "           6.4153e-01,  3.8159e-01]],\n",
              "\n",
              "        [[-1.1920e-01,  1.0604e-01,  1.2198e-01,  ...,  6.6599e-02,\n",
              "          -4.8295e-03,  1.0054e-01],\n",
              "         [ 3.3430e-01,  8.0653e-01, -1.7929e-01,  ..., -7.5157e-01,\n",
              "           1.4196e-03, -1.8487e-01],\n",
              "         [ 3.7542e-01,  8.1249e-01,  1.9379e-01,  ..., -8.3880e-01,\n",
              "          -3.9917e-01,  6.2898e-01],\n",
              "         ...,\n",
              "         [-1.9551e-01, -1.8690e-03, -3.9477e-01,  ...,  1.7064e-01,\n",
              "           4.6471e-01,  4.2169e-01],\n",
              "         [-1.9551e-01, -1.8690e-03, -3.9477e-01,  ...,  1.7064e-01,\n",
              "           4.6471e-01,  4.2169e-01],\n",
              "         [-1.9551e-01, -1.8690e-03, -3.9477e-01,  ...,  1.7064e-01,\n",
              "           4.6471e-01,  4.2169e-01]]], device='cuda:0'), tensor([[[-0.0419,  0.1793,  0.0958,  ...,  0.0049,  0.0669,  0.0315],\n",
              "         [-0.4429, -0.5334,  0.2767,  ...,  0.0214,  0.3214,  0.3499],\n",
              "         [-0.4092,  0.7864,  0.2469,  ..., -1.3569, -0.5882,  0.2521],\n",
              "         ...,\n",
              "         [-0.1404, -0.0666, -0.4027,  ..., -0.0490,  0.2726,  0.2585],\n",
              "         [-0.1404, -0.0666, -0.4027,  ..., -0.0490,  0.2726,  0.2585],\n",
              "         [-0.1404, -0.0666, -0.4027,  ..., -0.0490,  0.2726,  0.2585]],\n",
              "\n",
              "        [[-0.0328,  0.1228,  0.0884,  ...,  0.0377,  0.0811,  0.0413],\n",
              "         [-0.2807,  0.0271, -0.0125,  ...,  0.2261, -0.0394,  0.4176],\n",
              "         [ 0.2700,  1.7457,  0.0485,  ...,  0.2629, -0.1311, -0.0120],\n",
              "         ...,\n",
              "         [-0.0943, -0.3197, -0.2376,  ...,  0.2378,  0.3223,  0.2645],\n",
              "         [-0.0943, -0.3197, -0.2376,  ...,  0.2378,  0.3223,  0.2645],\n",
              "         [-0.0943, -0.3197, -0.2376,  ...,  0.2378,  0.3223,  0.2645]],\n",
              "\n",
              "        [[-0.0336,  0.1694,  0.1253,  ...,  0.0304,  0.0380,  0.0406],\n",
              "         [-0.4378, -0.3814,  0.3784,  ...,  0.1543,  0.1365, -0.1102],\n",
              "         [-0.2943,  0.7857,  0.5357,  ..., -0.3440,  0.0348, -0.0382],\n",
              "         ...,\n",
              "         [-0.2824, -0.2627, -0.1961,  ..., -0.0047,  0.3199,  0.2469],\n",
              "         [-0.2824, -0.2627, -0.1961,  ..., -0.0047,  0.3199,  0.2469],\n",
              "         [-0.2824, -0.2627, -0.1961,  ..., -0.0047,  0.3199,  0.2469]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-0.0410,  0.1756,  0.1167,  ...,  0.0111,  0.0518,  0.0253],\n",
              "         [-0.3452, -0.1997,  0.1992,  ...,  0.1064,  0.2495,  0.1086],\n",
              "         [ 0.0955, -0.3362,  0.3565,  ..., -0.7003, -0.0605,  0.5975],\n",
              "         ...,\n",
              "         [-0.1568, -0.1698, -0.3260,  ...,  0.0338,  0.3272,  0.2032],\n",
              "         [-0.1568, -0.1698, -0.3260,  ...,  0.0338,  0.3272,  0.2032],\n",
              "         [-0.1568, -0.1698, -0.3260,  ...,  0.0338,  0.3272,  0.2032]],\n",
              "\n",
              "        [[-0.0467,  0.1697,  0.1164,  ...,  0.0242,  0.0573,  0.0305],\n",
              "         [-0.1141,  0.5755,  0.1719,  ..., -0.2860, -0.1668,  0.6732],\n",
              "         [-0.3198,  0.6309,  0.1552,  ..., -1.3506,  0.1946, -0.4793],\n",
              "         ...,\n",
              "         [-0.2885, -0.2382, -0.1685,  ...,  0.1845,  0.3011,  0.1694],\n",
              "         [-0.2885, -0.2382, -0.1685,  ...,  0.1845,  0.3011,  0.1694],\n",
              "         [-0.2885, -0.2382, -0.1685,  ...,  0.1845,  0.3011,  0.1694]],\n",
              "\n",
              "        [[-0.0301,  0.1285,  0.0868,  ...,  0.0438,  0.0724,  0.0452],\n",
              "         [ 0.0925,  1.3279, -0.0798,  ..., -0.4082, -0.1631, -0.6641],\n",
              "         [ 0.2587,  1.1512,  0.1484,  ..., -0.4348, -0.3400,  0.4255],\n",
              "         ...,\n",
              "         [-0.1132, -0.1962, -0.3570,  ...,  0.1576,  0.3639,  0.2876],\n",
              "         [-0.1132, -0.1962, -0.3570,  ...,  0.1576,  0.3639,  0.2876],\n",
              "         [-0.1132, -0.1962, -0.3570,  ...,  0.1576,  0.3639,  0.2876]]],\n",
              "       device='cuda:0'), tensor([[[ 3.7579e-02,  1.0549e-01,  1.0338e-01,  ...,  1.1067e-01,\n",
              "          -1.5163e-02,  1.2332e-03],\n",
              "         [-4.5655e-01, -9.7092e-01, -2.0679e-01,  ..., -3.1571e-02,\n",
              "           1.2513e-01,  1.4234e-01],\n",
              "         [-1.1328e-01,  6.6164e-01,  3.6296e-01,  ..., -1.3326e+00,\n",
              "          -1.1682e+00,  6.2002e-03],\n",
              "         ...,\n",
              "         [-4.8897e-01, -3.0863e-01,  2.1291e-01,  ...,  2.1997e-02,\n",
              "           3.7403e-01,  1.2464e-02],\n",
              "         [-4.8897e-01, -3.0863e-01,  2.1291e-01,  ...,  2.1997e-02,\n",
              "           3.7403e-01,  1.2464e-02],\n",
              "         [-4.8897e-01, -3.0863e-01,  2.1291e-01,  ...,  2.1997e-02,\n",
              "           3.7403e-01,  1.2464e-02]],\n",
              "\n",
              "        [[ 5.8556e-02,  4.9460e-02,  1.0368e-01,  ...,  9.9058e-02,\n",
              "          -1.1901e-03, -1.1732e-02],\n",
              "         [-7.4651e-02, -7.1722e-02, -3.1079e-01,  ...,  5.0225e-02,\n",
              "          -1.0022e-01,  2.1355e-01],\n",
              "         [ 2.0153e-01,  1.6443e+00,  1.5316e-01,  ..., -1.2402e-01,\n",
              "          -9.6164e-02, -5.5018e-01],\n",
              "         ...,\n",
              "         [-1.9251e-01, -3.6660e-01,  1.4982e-01,  ...,  3.0789e-01,\n",
              "           1.2261e-01, -1.2331e-01],\n",
              "         [-1.9251e-01, -3.6660e-01,  1.4982e-01,  ...,  3.0789e-01,\n",
              "           1.2261e-01, -1.2331e-01],\n",
              "         [-1.9251e-01, -3.6660e-01,  1.4982e-01,  ...,  3.0789e-01,\n",
              "           1.2261e-01, -1.2331e-01]],\n",
              "\n",
              "        [[ 8.8260e-02,  8.4926e-02,  1.1396e-01,  ...,  1.3234e-01,\n",
              "          -2.3557e-02, -9.7122e-03],\n",
              "         [-5.0374e-01, -6.4928e-01,  7.9633e-02,  ...,  6.0169e-02,\n",
              "          -1.7810e-01, -4.0930e-01],\n",
              "         [ 7.8206e-01,  1.1631e+00,  4.6313e-01,  ..., -3.1383e-02,\n",
              "          -1.1502e-01, -2.5700e-01],\n",
              "         ...,\n",
              "         [-3.2273e-01, -3.0336e-01,  3.4878e-01,  ...,  2.6184e-02,\n",
              "           1.4769e-01, -8.3457e-02],\n",
              "         [-3.2273e-01, -3.0336e-01,  3.4878e-01,  ...,  2.6184e-02,\n",
              "           1.4769e-01, -8.3457e-02],\n",
              "         [-3.2273e-01, -3.0336e-01,  3.4878e-01,  ...,  2.6184e-02,\n",
              "           1.4769e-01, -8.3457e-02]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 4.2471e-02,  1.0438e-01,  1.2084e-01,  ...,  1.0537e-01,\n",
              "           4.0036e-03, -1.5528e-03],\n",
              "         [-2.9746e-01, -6.1380e-01, -1.8063e-01,  ..., -8.6057e-02,\n",
              "           5.1962e-02, -2.3993e-01],\n",
              "         [-3.3861e-01, -6.5510e-01, -1.3535e-01,  ..., -8.7127e-01,\n",
              "          -1.1881e-01,  3.1772e-01],\n",
              "         ...,\n",
              "         [-6.2277e-01, -2.7744e-01,  3.0637e-01,  ...,  1.9869e-01,\n",
              "           3.9626e-01, -1.1308e-01],\n",
              "         [-6.2277e-01, -2.7744e-01,  3.0637e-01,  ...,  1.9869e-01,\n",
              "           3.9626e-01, -1.1308e-01],\n",
              "         [-6.2277e-01, -2.7744e-01,  3.0637e-01,  ...,  1.9869e-01,\n",
              "           3.9626e-01, -1.1308e-01]],\n",
              "\n",
              "        [[ 4.5176e-02,  1.0554e-01,  9.6401e-02,  ...,  1.2160e-01,\n",
              "          -1.3170e-02,  2.8671e-03],\n",
              "         [-4.3449e-01,  5.2821e-01,  4.0639e-02,  ..., -4.4366e-01,\n",
              "          -4.8940e-01,  2.7328e-02],\n",
              "         [-1.3439e-01,  4.6408e-01, -1.3023e-02,  ..., -1.5448e+00,\n",
              "          -3.1242e-01, -1.5324e-01],\n",
              "         ...,\n",
              "         [-5.3206e-01, -9.6240e-02,  3.1002e-01,  ...,  1.8306e-01,\n",
              "           2.6647e-01, -1.2434e-01],\n",
              "         [-5.3206e-01, -9.6240e-02,  3.1002e-01,  ...,  1.8306e-01,\n",
              "           2.6647e-01, -1.2434e-01],\n",
              "         [-5.3206e-01, -9.6240e-02,  3.1002e-01,  ...,  1.8306e-01,\n",
              "           2.6647e-01, -1.2434e-01]],\n",
              "\n",
              "        [[ 5.5775e-02,  4.9715e-02,  9.2323e-02,  ...,  1.2843e-01,\n",
              "           1.1562e-02, -1.7181e-02],\n",
              "         [ 1.5302e-01,  1.4833e+00, -2.1522e-01,  ..., -1.0681e+00,\n",
              "          -1.9466e-01, -1.1971e+00],\n",
              "         [ 9.7659e-01,  9.9389e-01, -1.3765e-01,  ..., -2.0315e-01,\n",
              "          -2.5210e-01,  1.8806e-02],\n",
              "         ...,\n",
              "         [-1.8695e-01, -3.0858e-01,  9.1979e-02,  ...,  2.0059e-01,\n",
              "           1.3378e-01, -1.5509e-01],\n",
              "         [-1.8695e-01, -3.0858e-01,  9.1979e-02,  ...,  2.0059e-01,\n",
              "           1.3378e-01, -1.5509e-01],\n",
              "         [-1.8695e-01, -3.0858e-01,  9.1979e-02,  ...,  2.0059e-01,\n",
              "           1.3378e-01, -1.5509e-01]]], device='cuda:0'), tensor([[[-0.0197,  0.0557,  0.0092,  ...,  0.1872, -0.1758,  0.1114],\n",
              "         [-0.0413, -0.9746,  0.2314,  ..., -0.0769, -0.0669,  0.1191],\n",
              "         [ 0.2762,  0.2319,  0.6505,  ..., -1.3363, -1.2554, -0.7664],\n",
              "         ...,\n",
              "         [ 0.2127, -0.5411, -0.0050,  ..., -0.0595, -0.1465, -0.0180],\n",
              "         [ 0.2127, -0.5411, -0.0050,  ..., -0.0595, -0.1465, -0.0180],\n",
              "         [ 0.2127, -0.5411, -0.0050,  ..., -0.0595, -0.1465, -0.0180]],\n",
              "\n",
              "        [[ 0.0122,  0.0148,  0.0743,  ...,  0.1501, -0.1296,  0.0994],\n",
              "         [-0.2263, -0.5635, -0.0641,  ...,  0.3700,  0.4058,  0.5791],\n",
              "         [ 0.0576,  0.7916,  0.2570,  ...,  0.6234,  0.2201,  0.0444],\n",
              "         ...,\n",
              "         [-0.1188, -0.3277,  0.0551,  ...,  0.5987, -0.1461,  0.5018],\n",
              "         [-0.1188, -0.3277,  0.0551,  ...,  0.5987, -0.1461,  0.5018],\n",
              "         [-0.1188, -0.3277,  0.0551,  ...,  0.5987, -0.1461,  0.5018]],\n",
              "\n",
              "        [[ 0.0257,  0.0800,  0.0705,  ...,  0.1771, -0.2090,  0.1382],\n",
              "         [-0.5074, -0.6029, -1.2337,  ..., -0.4050,  0.4007, -0.2052],\n",
              "         [-0.2131,  0.3635, -0.6014,  ..., -0.1529,  0.3713, -0.7324],\n",
              "         ...,\n",
              "         [-0.3811, -0.5431, -1.6048,  ..., -0.4799,  0.1085, -0.3617],\n",
              "         [-0.3811, -0.5431, -1.6048,  ..., -0.4799,  0.1085, -0.3617],\n",
              "         [-0.3811, -0.5431, -1.6048,  ..., -0.4799,  0.1085, -0.3617]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.0122,  0.0369,  0.0512,  ...,  0.1708, -0.1510,  0.0916],\n",
              "         [ 0.3360, -0.9065,  0.4725,  ...,  0.1210, -0.0822, -0.0658],\n",
              "         [-0.0542, -0.7208,  0.4033,  ..., -0.7419, -0.0844,  0.0082],\n",
              "         ...,\n",
              "         [ 0.1629, -0.5853,  0.3126,  ...,  0.1048, -0.1576, -0.1642],\n",
              "         [ 0.1629, -0.5853,  0.3126,  ...,  0.1048, -0.1576, -0.1642],\n",
              "         [ 0.1629, -0.5853,  0.3126,  ...,  0.1048, -0.1576, -0.1642]],\n",
              "\n",
              "        [[ 0.0168,  0.0552,  0.0295,  ...,  0.1883, -0.1611,  0.0919],\n",
              "         [-0.1030,  0.3231,  0.2139,  ..., -0.3076, -0.2307, -0.0174],\n",
              "         [-0.2121,  0.4984,  0.1818,  ..., -1.0650, -0.5513,  0.4486],\n",
              "         ...,\n",
              "         [ 0.2193, -0.1220,  0.2412,  ...,  0.2011, -0.2707, -0.0397],\n",
              "         [ 0.2193, -0.1220,  0.2412,  ...,  0.2011, -0.2707, -0.0397],\n",
              "         [ 0.2193, -0.1220,  0.2412,  ...,  0.2011, -0.2707, -0.0397]],\n",
              "\n",
              "        [[ 0.0183,  0.0187,  0.0553,  ...,  0.1909, -0.1372,  0.1065],\n",
              "         [ 0.0979,  1.1235,  0.0791,  ..., -0.1904, -0.1645, -0.9528],\n",
              "         [-0.2077,  1.1162,  0.3825,  ..., -0.3896,  0.0083,  0.0296],\n",
              "         ...,\n",
              "         [-0.0573, -0.3571,  0.0168,  ...,  0.6645, -0.0746,  0.4140],\n",
              "         [-0.0573, -0.3571,  0.0168,  ...,  0.6645, -0.0746,  0.4140],\n",
              "         [-0.0573, -0.3571,  0.0168,  ...,  0.6645, -0.0746,  0.4140]]],\n",
              "       device='cuda:0'), tensor([[[-8.3573e-02,  2.8929e-02, -1.0098e-01,  ...,  2.5122e-01,\n",
              "          -1.7328e-02,  1.2290e-01],\n",
              "         [-2.4262e-01, -1.4524e+00,  4.0850e-01,  ...,  4.5598e-01,\n",
              "           1.3568e-01, -5.4409e-01],\n",
              "         [-9.6848e-02, -4.9028e-01,  5.8307e-01,  ..., -1.0926e-01,\n",
              "          -8.0825e-02, -6.6217e-01],\n",
              "         ...,\n",
              "         [ 4.5714e-01, -7.4769e-01,  9.1147e-01,  ..., -6.8648e-02,\n",
              "           6.0595e-01, -6.6061e-01],\n",
              "         [ 4.5714e-01, -7.4769e-01,  9.1147e-01,  ..., -6.8648e-02,\n",
              "           6.0595e-01, -6.6061e-01],\n",
              "         [ 4.5714e-01, -7.4769e-01,  9.1147e-01,  ..., -6.8648e-02,\n",
              "           6.0595e-01, -6.6061e-01]],\n",
              "\n",
              "        [[ 7.1727e-03,  2.5153e-02, -8.9827e-02,  ...,  5.2892e-02,\n",
              "           5.7634e-03,  5.2154e-02],\n",
              "         [ 3.2703e-02, -9.9802e-02,  8.0678e-03,  ...,  1.2376e-01,\n",
              "           2.5625e-01, -1.4683e-01],\n",
              "         [ 1.9549e-01,  9.5864e-02,  2.3461e-02,  ...,  2.5547e-02,\n",
              "           2.4249e-01, -2.7422e-01],\n",
              "         ...,\n",
              "         [ 2.0745e-01, -1.4803e-01,  1.2549e-01,  ...,  7.9650e-02,\n",
              "          -9.8872e-04, -1.3078e-01],\n",
              "         [ 2.0745e-01, -1.4803e-01,  1.2549e-01,  ...,  7.9650e-02,\n",
              "          -9.8872e-04, -1.3078e-01],\n",
              "         [ 2.0745e-01, -1.4803e-01,  1.2549e-01,  ...,  7.9650e-02,\n",
              "          -9.8872e-04, -1.3078e-01]],\n",
              "\n",
              "        [[-1.4261e-02,  9.6821e-02, -8.2576e-02,  ...,  2.1108e-01,\n",
              "          -7.7121e-02,  1.6590e-01],\n",
              "         [-3.3565e-02, -7.6232e-01, -1.1198e+00,  ..., -5.7216e-01,\n",
              "           1.0064e-01,  1.9193e-01],\n",
              "         [ 2.7275e-01,  2.5872e-01, -4.0601e-01,  ..., -3.2874e-01,\n",
              "           1.2061e-01, -3.2888e-01],\n",
              "         ...,\n",
              "         [ 4.4714e-01, -8.5961e-01, -1.1842e+00,  ..., -5.3065e-01,\n",
              "           6.5217e-02, -6.8602e-03],\n",
              "         [ 4.4714e-01, -8.5961e-01, -1.1842e+00,  ..., -5.3065e-01,\n",
              "           6.5217e-02, -6.8602e-03],\n",
              "         [ 4.4714e-01, -8.5961e-01, -1.1842e+00,  ..., -5.3065e-01,\n",
              "           6.5217e-02, -6.8602e-03]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-4.9563e-02, -7.3474e-02, -1.0648e-01,  ...,  3.2150e-01,\n",
              "           7.1173e-02,  8.9048e-02],\n",
              "         [-1.5564e-01, -1.9118e+00,  4.8274e-01,  ...,  7.8447e-01,\n",
              "          -9.3553e-02, -3.6791e-02],\n",
              "         [-1.8170e-01, -1.0386e+00,  5.5106e-01,  ...,  1.5401e-01,\n",
              "           1.7426e-01,  2.6838e-01],\n",
              "         ...,\n",
              "         [ 3.8720e-01, -1.2881e+00,  7.4853e-01,  ...,  7.3568e-01,\n",
              "           7.6681e-01, -4.1376e-01],\n",
              "         [ 3.8720e-01, -1.2881e+00,  7.4853e-01,  ...,  7.3568e-01,\n",
              "           7.6681e-01, -4.1376e-01],\n",
              "         [ 3.8720e-01, -1.2881e+00,  7.4853e-01,  ...,  7.3568e-01,\n",
              "           7.6681e-01, -4.1376e-01]],\n",
              "\n",
              "        [[-5.0701e-02,  1.7301e-02, -1.3599e-01,  ...,  2.8599e-01,\n",
              "           2.6385e-02,  1.0872e-01],\n",
              "         [-3.3693e-01, -3.8114e-01,  3.7973e-01,  ...,  4.1088e-01,\n",
              "           2.3652e-01, -4.0754e-02],\n",
              "         [-3.2238e-01, -4.7661e-01,  7.1516e-02,  ..., -2.0422e-01,\n",
              "           4.1274e-02,  2.9147e-01],\n",
              "         ...,\n",
              "         [ 4.4544e-01, -1.1465e+00,  6.3329e-01,  ...,  6.7821e-01,\n",
              "           8.6073e-01, -2.8454e-01],\n",
              "         [ 4.4544e-01, -1.1465e+00,  6.3329e-01,  ...,  6.7821e-01,\n",
              "           8.6073e-01, -2.8454e-01],\n",
              "         [ 4.4544e-01, -1.1465e+00,  6.3329e-01,  ...,  6.7821e-01,\n",
              "           8.6073e-01, -2.8454e-01]],\n",
              "\n",
              "        [[ 2.6986e-03,  4.1007e-02, -7.3746e-02,  ...,  1.1750e-01,\n",
              "          -1.6172e-02,  1.2347e-01],\n",
              "         [ 2.9800e-01,  2.9298e-01,  1.3015e-01,  ..., -1.1618e-01,\n",
              "           1.3623e-01, -3.5783e-01],\n",
              "         [ 3.4123e-01,  2.9604e-01,  1.9382e-01,  ..., -9.3829e-02,\n",
              "           2.0866e-01, -2.9129e-01],\n",
              "         ...,\n",
              "         [ 2.2874e-01, -1.0940e-01,  6.5589e-02,  ...,  6.6056e-02,\n",
              "           4.8239e-02, -1.7214e-01],\n",
              "         [ 2.2874e-01, -1.0940e-01,  6.5589e-02,  ...,  6.6056e-02,\n",
              "           4.8239e-02, -1.7214e-01],\n",
              "         [ 2.2874e-01, -1.0940e-01,  6.5589e-02,  ...,  6.6056e-02,\n",
              "           4.8239e-02, -1.7214e-01]]], device='cuda:0'), tensor([[[-1.4166e-02, -1.5715e-01, -1.0213e-01,  ...,  1.8805e-02,\n",
              "          -5.5414e-02,  9.2102e-02],\n",
              "         [ 3.1139e-01, -1.9095e+00,  6.3167e-02,  ..., -9.8770e-02,\n",
              "           1.6392e-01, -2.9903e-01],\n",
              "         [ 4.4657e-01, -1.0234e+00, -1.7761e-01,  ..., -3.7369e-02,\n",
              "           3.2291e-01, -9.1572e-02],\n",
              "         ...,\n",
              "         [ 3.1362e-02, -1.7086e+00,  5.5500e-01,  ..., -1.0239e-01,\n",
              "           5.1135e-01, -2.3371e-01],\n",
              "         [ 3.1362e-02, -1.7086e+00,  5.5500e-01,  ..., -1.0239e-01,\n",
              "           5.1135e-01, -2.3371e-01],\n",
              "         [ 3.1362e-02, -1.7086e+00,  5.5500e-01,  ..., -1.0239e-01,\n",
              "           5.1135e-01, -2.3371e-01]],\n",
              "\n",
              "        [[ 1.1142e-01,  1.1724e-01, -1.6724e-01,  ...,  1.4852e-01,\n",
              "           1.0340e-02,  6.8379e-03],\n",
              "         [ 6.8460e-02,  1.5887e-01, -2.9055e-02,  ...,  1.7550e-01,\n",
              "           2.6792e-02, -1.1233e-01],\n",
              "         [ 6.7412e-02,  1.8038e-01, -3.6191e-02,  ...,  1.7161e-01,\n",
              "           1.5001e-02, -1.1978e-01],\n",
              "         ...,\n",
              "         [ 5.7620e-02,  1.5976e-01, -6.2142e-02,  ...,  1.7622e-01,\n",
              "           1.3264e-02, -8.3854e-02],\n",
              "         [ 5.7620e-02,  1.5976e-01, -6.2142e-02,  ...,  1.7622e-01,\n",
              "           1.3264e-02, -8.3854e-02],\n",
              "         [ 5.7620e-02,  1.5976e-01, -6.2142e-02,  ...,  1.7622e-01,\n",
              "           1.3264e-02, -8.3854e-02]],\n",
              "\n",
              "        [[ 8.8327e-02,  4.0467e-04, -2.8324e-02,  ...,  4.6505e-02,\n",
              "          -1.8753e-02,  3.2948e-02],\n",
              "         [ 6.4652e-02, -1.1564e+00, -7.4027e-01,  ..., -2.6937e-01,\n",
              "          -8.8396e-02,  8.4185e-02],\n",
              "         [ 1.5407e-01, -1.8045e-01, -8.7522e-01,  ..., -3.5077e-01,\n",
              "           9.9554e-02, -2.5591e-01],\n",
              "         ...,\n",
              "         [ 1.8278e-01, -1.4063e+00, -9.1906e-01,  ..., -4.4297e-01,\n",
              "          -2.8814e-01,  4.3348e-02],\n",
              "         [ 1.8278e-01, -1.4063e+00, -9.1906e-01,  ..., -4.4297e-01,\n",
              "          -2.8814e-01,  4.3348e-02],\n",
              "         [ 1.8278e-01, -1.4063e+00, -9.1906e-01,  ..., -4.4297e-01,\n",
              "          -2.8814e-01,  4.3348e-02]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 4.0025e-02, -1.2041e-01, -8.2306e-02,  ...,  3.8809e-02,\n",
              "          -3.1370e-02,  5.8517e-02],\n",
              "         [ 1.3305e-01, -2.2019e+00,  2.2543e-01,  ...,  5.8020e-02,\n",
              "          -1.6078e-01, -2.0127e-01],\n",
              "         [-1.4551e-01, -1.6277e+00,  8.4105e-02,  ...,  1.1252e-01,\n",
              "           9.2766e-02,  3.1788e-01],\n",
              "         ...,\n",
              "         [ 1.2169e-01, -1.9266e+00,  4.4803e-01,  ...,  2.7887e-01,\n",
              "           4.9255e-01, -2.7272e-01],\n",
              "         [ 1.2169e-01, -1.9266e+00,  4.4803e-01,  ...,  2.7887e-01,\n",
              "           4.9255e-01, -2.7272e-01],\n",
              "         [ 1.2169e-01, -1.9266e+00,  4.4803e-01,  ...,  2.7887e-01,\n",
              "           4.9255e-01, -2.7272e-01]],\n",
              "\n",
              "        [[ 1.0140e-02, -9.9100e-02, -8.5786e-02,  ...,  5.3567e-02,\n",
              "          -6.4075e-02,  6.4659e-02],\n",
              "         [ 3.5095e-01, -9.2838e-01, -1.4963e-01,  ...,  1.7951e-01,\n",
              "           3.6812e-01, -9.0827e-02],\n",
              "         [ 2.5439e-01, -1.2152e+00,  1.1051e-01,  ...,  1.0738e-03,\n",
              "           1.6312e-01, -6.8525e-03],\n",
              "         ...,\n",
              "         [ 2.2236e-01, -1.6510e+00,  5.8733e-01,  ...,  4.4808e-01,\n",
              "           4.8619e-01, -1.7923e-01],\n",
              "         [ 2.2236e-01, -1.6510e+00,  5.8733e-01,  ...,  4.4808e-01,\n",
              "           4.8619e-01, -1.7923e-01],\n",
              "         [ 2.2236e-01, -1.6510e+00,  5.8733e-01,  ...,  4.4808e-01,\n",
              "           4.8619e-01, -1.7923e-01]],\n",
              "\n",
              "        [[ 1.1363e-01,  8.4141e-02, -1.5373e-01,  ...,  1.2053e-01,\n",
              "          -2.1841e-03,  2.9417e-02],\n",
              "         [ 1.1811e-01,  1.4446e-01, -8.9102e-02,  ...,  1.5812e-01,\n",
              "           2.4876e-02, -7.9714e-02],\n",
              "         [ 3.7223e-02,  1.8381e-01, -4.2113e-02,  ...,  1.4992e-01,\n",
              "           2.0666e-03, -6.8499e-02],\n",
              "         ...,\n",
              "         [ 5.8091e-02,  1.6199e-01, -4.2744e-02,  ...,  1.5768e-01,\n",
              "           1.2003e-02, -9.4890e-02],\n",
              "         [ 5.8091e-02,  1.6199e-01, -4.2744e-02,  ...,  1.5768e-01,\n",
              "           1.2003e-02, -9.4890e-02],\n",
              "         [ 5.8091e-02,  1.6199e-01, -4.2744e-02,  ...,  1.5768e-01,\n",
              "           1.2003e-02, -9.4890e-02]]], device='cuda:0'), tensor([[[-3.3210e-02,  4.3796e-02, -1.0224e-02,  ...,  5.6687e-02,\n",
              "           2.1032e-02, -5.9581e-02],\n",
              "         [ 4.8679e-01, -1.7378e+00,  6.4834e-01,  ..., -1.2736e-01,\n",
              "           1.1037e+00, -1.3926e-01],\n",
              "         [ 1.0785e+00, -6.4752e-01,  4.5120e-01,  ...,  1.0795e-01,\n",
              "           9.7320e-01, -2.1967e-01],\n",
              "         ...,\n",
              "         [ 5.5675e-01, -1.2644e+00,  7.6164e-01,  ...,  9.8860e-02,\n",
              "           1.0310e+00, -3.8640e-02],\n",
              "         [ 5.5675e-01, -1.2644e+00,  7.6164e-01,  ...,  9.8860e-02,\n",
              "           1.0310e+00, -3.8640e-02],\n",
              "         [ 5.5675e-01, -1.2644e+00,  7.6164e-01,  ...,  9.8860e-02,\n",
              "           1.0310e+00, -3.8640e-02]],\n",
              "\n",
              "        [[ 2.0721e-02,  2.2408e-01, -1.0451e-01,  ...,  7.1879e-02,\n",
              "          -4.8780e-02, -7.6726e-02],\n",
              "         [-1.0299e-02,  2.4497e-01, -7.3242e-02,  ...,  8.1424e-02,\n",
              "          -4.7371e-02, -7.5390e-02],\n",
              "         [-1.1807e-02,  2.5135e-01, -7.8585e-02,  ...,  7.9103e-02,\n",
              "          -4.9110e-02, -7.6575e-02],\n",
              "         ...,\n",
              "         [-8.6915e-03,  2.4963e-01, -8.5104e-02,  ...,  8.3106e-02,\n",
              "          -5.0626e-02, -7.2558e-02],\n",
              "         [-8.6915e-03,  2.4963e-01, -8.5104e-02,  ...,  8.3106e-02,\n",
              "          -5.0626e-02, -7.2558e-02],\n",
              "         [-8.6915e-03,  2.4963e-01, -8.5104e-02,  ...,  8.3106e-02,\n",
              "          -5.0626e-02, -7.2558e-02]],\n",
              "\n",
              "        [[ 9.3826e-02,  2.9230e-02,  8.8390e-02,  ..., -1.0556e-02,\n",
              "          -3.6669e-02, -1.7724e-02],\n",
              "         [ 2.1152e-01, -1.2745e+00, -7.9574e-01,  ...,  6.1642e-02,\n",
              "          -2.7479e-01, -7.3595e-01],\n",
              "         [-1.1336e-01, -1.2893e-01, -6.4452e-01,  ..., -2.0683e-01,\n",
              "           1.2148e-01, -3.4995e-01],\n",
              "         ...,\n",
              "         [ 1.7721e-01, -1.4013e+00, -1.5323e-01,  ..., -2.6272e-01,\n",
              "          -2.6054e-01, -3.8616e-01],\n",
              "         [ 1.7721e-01, -1.4013e+00, -1.5323e-01,  ..., -2.6272e-01,\n",
              "          -2.6054e-01, -3.8616e-01],\n",
              "         [ 1.7721e-01, -1.4013e+00, -1.5323e-01,  ..., -2.6272e-01,\n",
              "          -2.6054e-01, -3.8616e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-5.6895e-02,  4.1593e-02, -2.1532e-02,  ...,  6.3010e-02,\n",
              "          -1.5715e-03, -4.5977e-02],\n",
              "         [ 3.4174e-01, -2.1190e+00,  4.8719e-01,  ...,  2.4154e-02,\n",
              "           9.2141e-01,  4.9163e-02],\n",
              "         [ 6.2638e-01, -1.6119e+00,  5.4434e-01,  ...,  1.7294e-01,\n",
              "           1.1538e+00,  3.3094e-01],\n",
              "         ...,\n",
              "         [ 6.4885e-01, -1.5985e+00,  6.8499e-01,  ...,  1.7990e-01,\n",
              "           7.1715e-01, -9.3496e-03],\n",
              "         [ 6.4885e-01, -1.5985e+00,  6.8499e-01,  ...,  1.7990e-01,\n",
              "           7.1715e-01, -9.3496e-03],\n",
              "         [ 6.4885e-01, -1.5985e+00,  6.8499e-01,  ...,  1.7990e-01,\n",
              "           7.1715e-01, -9.3496e-03]],\n",
              "\n",
              "        [[-6.6867e-02,  5.2368e-02, -2.4057e-02,  ...,  5.7906e-02,\n",
              "          -7.7811e-03, -3.3844e-02],\n",
              "         [ 7.3389e-01, -1.0580e+00,  2.6964e-01,  ...,  1.3726e-01,\n",
              "           8.8721e-01, -5.6144e-02],\n",
              "         [ 5.0960e-01, -1.4082e+00,  5.3016e-01,  ...,  4.8267e-02,\n",
              "           9.4876e-01,  2.7707e-01],\n",
              "         ...,\n",
              "         [ 5.9350e-01, -1.4258e+00,  6.3454e-01,  ...,  2.7294e-01,\n",
              "           9.1647e-01,  1.0484e-01],\n",
              "         [ 5.9350e-01, -1.4258e+00,  6.3454e-01,  ...,  2.7294e-01,\n",
              "           9.1647e-01,  1.0484e-01],\n",
              "         [ 5.9350e-01, -1.4258e+00,  6.3454e-01,  ...,  2.7294e-01,\n",
              "           9.1647e-01,  1.0484e-01]],\n",
              "\n",
              "        [[ 1.7988e-02,  2.0362e-01, -9.0630e-02,  ...,  6.0300e-02,\n",
              "          -4.9724e-02, -7.6437e-02],\n",
              "         [-4.8263e-03,  2.2810e-01, -5.6892e-02,  ...,  9.0049e-02,\n",
              "          -4.8692e-02, -8.2742e-02],\n",
              "         [-1.5940e-02,  2.4436e-01, -6.9958e-02,  ...,  7.8741e-02,\n",
              "          -4.9954e-02, -8.0907e-02],\n",
              "         ...,\n",
              "         [-1.0838e-02,  2.3932e-01, -6.7206e-02,  ...,  7.5932e-02,\n",
              "          -4.7832e-02, -7.1774e-02],\n",
              "         [-1.0838e-02,  2.3932e-01, -6.7206e-02,  ...,  7.5932e-02,\n",
              "          -4.7832e-02, -7.1774e-02],\n",
              "         [-1.0838e-02,  2.3932e-01, -6.7206e-02,  ...,  7.5932e-02,\n",
              "          -4.7832e-02, -7.1774e-02]]], device='cuda:0'), tensor([[[-0.0612,  0.0077, -0.0520,  ...,  0.0352,  0.0306, -0.0347],\n",
              "         [ 0.1103, -1.2230,  0.1998,  ...,  0.7071,  0.0876,  0.0820],\n",
              "         [ 0.5145, -0.7702,  0.0475,  ...,  0.6862,  0.0483,  0.0275],\n",
              "         ...,\n",
              "         [ 0.3536, -1.0420,  0.3523,  ...,  0.7512, -0.0418,  0.1290],\n",
              "         [ 0.3536, -1.0420,  0.3523,  ...,  0.7512, -0.0418,  0.1290],\n",
              "         [ 0.3536, -1.0420,  0.3523,  ...,  0.7512, -0.0418,  0.1290]],\n",
              "\n",
              "        [[-0.0030,  0.1564, -0.3724,  ...,  0.2330,  0.0332, -0.1506],\n",
              "         [-0.0188,  0.1641, -0.3613,  ...,  0.2505,  0.0418, -0.1460],\n",
              "         [-0.0195,  0.1664, -0.3626,  ...,  0.2486,  0.0426, -0.1452],\n",
              "         ...,\n",
              "         [-0.0188,  0.1673, -0.3655,  ...,  0.2500,  0.0426, -0.1457],\n",
              "         [-0.0188,  0.1673, -0.3655,  ...,  0.2500,  0.0426, -0.1457],\n",
              "         [-0.0188,  0.1673, -0.3655,  ...,  0.2500,  0.0426, -0.1457]],\n",
              "\n",
              "        [[-0.1633,  0.0668, -0.0403,  ...,  0.0167,  0.0954,  0.0944],\n",
              "         [ 0.0682, -0.4594, -0.3355,  ..., -0.3224,  0.1351, -0.0304],\n",
              "         [-0.0329, -0.1685, -0.2131,  ..., -0.2257,  0.1502, -0.0483],\n",
              "         ...,\n",
              "         [-0.1771, -0.3668, -0.1538,  ..., -0.3482,  0.0798,  0.1884],\n",
              "         [-0.1771, -0.3668, -0.1538,  ..., -0.3482,  0.0798,  0.1884],\n",
              "         [-0.1771, -0.3668, -0.1538,  ..., -0.3482,  0.0798,  0.1884]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-0.0637,  0.0078, -0.0446,  ...,  0.0333,  0.0257, -0.0260],\n",
              "         [ 0.0329, -1.3854,  0.3731,  ...,  0.7600,  0.0594,  0.3023],\n",
              "         [ 0.1986, -1.1956,  0.4525,  ...,  0.7478,  0.2453,  0.2382],\n",
              "         ...,\n",
              "         [ 0.2574, -1.2455,  0.4258,  ...,  0.7653, -0.0363,  0.1088],\n",
              "         [ 0.2574, -1.2455,  0.4258,  ...,  0.7653, -0.0363,  0.1088],\n",
              "         [ 0.2574, -1.2455,  0.4258,  ...,  0.7653, -0.0363,  0.1088]],\n",
              "\n",
              "        [[-0.0673,  0.0056, -0.0492,  ...,  0.0346,  0.0278, -0.0296],\n",
              "         [ 0.0612, -1.0421,  0.3864,  ...,  0.7896,  0.0187,  0.1485],\n",
              "         [ 0.1090, -1.2659,  0.4711,  ...,  0.8103,  0.1250,  0.5163],\n",
              "         ...,\n",
              "         [ 0.2099, -1.1142,  0.4592,  ...,  0.8057, -0.0627,  0.3369],\n",
              "         [ 0.2099, -1.1142,  0.4592,  ...,  0.8057, -0.0627,  0.3369],\n",
              "         [ 0.2099, -1.1142,  0.4592,  ...,  0.8057, -0.0627,  0.3369]],\n",
              "\n",
              "        [[-0.0123,  0.1475, -0.3590,  ...,  0.2219,  0.0314, -0.1467],\n",
              "         [-0.0344,  0.1573, -0.3500,  ...,  0.2404,  0.0323, -0.1473],\n",
              "         [-0.0356,  0.1602, -0.3501,  ...,  0.2357,  0.0377, -0.1419],\n",
              "         ...,\n",
              "         [-0.0300,  0.1594, -0.3505,  ...,  0.2392,  0.0426, -0.1414],\n",
              "         [-0.0300,  0.1594, -0.3505,  ...,  0.2392,  0.0426, -0.1414],\n",
              "         [-0.0300,  0.1594, -0.3505,  ...,  0.2392,  0.0426, -0.1414]]],\n",
              "       device='cuda:0'), tensor([[[ 0.1435, -0.0384,  0.0321,  ..., -0.1215,  0.1260, -0.0105],\n",
              "         [-0.5765, -0.3151, -0.1523,  ...,  0.3185,  0.5111,  0.2704],\n",
              "         [-0.7253, -0.2357, -0.0720,  ...,  0.2879,  0.4711,  0.2628],\n",
              "         ...,\n",
              "         [-0.4053, -0.2562, -0.1317,  ...,  0.2739,  0.3828,  0.3230],\n",
              "         [-0.4053, -0.2562, -0.1317,  ...,  0.2739,  0.3828,  0.3230],\n",
              "         [-0.4053, -0.2562, -0.1317,  ...,  0.2739,  0.3828,  0.3230]],\n",
              "\n",
              "        [[-0.2060,  0.1627, -0.1138,  ...,  0.3920, -0.1770, -0.1426],\n",
              "         [-0.2117,  0.1675, -0.1139,  ...,  0.4055, -0.1743, -0.1479],\n",
              "         [-0.2122,  0.1681, -0.1141,  ...,  0.4046, -0.1739, -0.1479],\n",
              "         ...,\n",
              "         [-0.2113,  0.1682, -0.1152,  ...,  0.4046, -0.1737, -0.1475],\n",
              "         [-0.2113,  0.1682, -0.1152,  ...,  0.4046, -0.1737, -0.1475],\n",
              "         [-0.2113,  0.1682, -0.1152,  ...,  0.4046, -0.1737, -0.1475]],\n",
              "\n",
              "        [[ 0.1730,  0.7065, -0.7173,  ..., -0.6045, -0.0342,  0.4584],\n",
              "         [-0.1721,  0.5410, -0.8914,  ..., -0.8307,  0.1751,  0.4636],\n",
              "         [ 0.1275,  0.6222, -0.7378,  ..., -0.7438,  0.1554,  0.4428],\n",
              "         ...,\n",
              "         [-0.1066,  0.4203, -0.9314,  ..., -0.8678,  0.0328,  0.6338],\n",
              "         [-0.1066,  0.4203, -0.9314,  ..., -0.8678,  0.0328,  0.6338],\n",
              "         [-0.1066,  0.4203, -0.9314,  ..., -0.8678,  0.0328,  0.6338]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.1471, -0.0319,  0.0263,  ..., -0.1235,  0.1241, -0.0086],\n",
              "         [-0.5364, -0.2446, -0.1571,  ...,  0.3026,  0.4520,  0.3592],\n",
              "         [-0.5345, -0.1389, -0.1523,  ...,  0.2823,  0.4996,  0.3525],\n",
              "         ...,\n",
              "         [-0.4070, -0.2530, -0.0950,  ...,  0.2378,  0.3578,  0.3148],\n",
              "         [-0.4070, -0.2530, -0.0950,  ...,  0.2378,  0.3578,  0.3148],\n",
              "         [-0.4070, -0.2530, -0.0950,  ...,  0.2378,  0.3578,  0.3148]],\n",
              "\n",
              "        [[ 0.1461, -0.0331,  0.0330,  ..., -0.1212,  0.1175, -0.0065],\n",
              "         [-0.7088, -0.0286, -0.0579,  ...,  0.3236,  0.5132,  0.3219],\n",
              "         [-0.6511, -0.1380,  0.0260,  ...,  0.3178,  0.5178,  0.3353],\n",
              "         ...,\n",
              "         [-0.3456, -0.1019, -0.1010,  ...,  0.2297,  0.3165,  0.3817],\n",
              "         [-0.3456, -0.1019, -0.1010,  ...,  0.2297,  0.3165,  0.3817],\n",
              "         [-0.3456, -0.1019, -0.1010,  ...,  0.2297,  0.3165,  0.3817]],\n",
              "\n",
              "        [[-0.1944,  0.1514, -0.0949,  ...,  0.3475, -0.1693, -0.1280],\n",
              "         [-0.2033,  0.1570, -0.0983,  ...,  0.3626, -0.1698, -0.1352],\n",
              "         [-0.2044,  0.1583, -0.0985,  ...,  0.3604, -0.1664, -0.1343],\n",
              "         ...,\n",
              "         [-0.2015,  0.1576, -0.0968,  ...,  0.3607, -0.1656, -0.1335],\n",
              "         [-0.2015,  0.1576, -0.0968,  ...,  0.3607, -0.1656, -0.1335],\n",
              "         [-0.2015,  0.1576, -0.0968,  ...,  0.3607, -0.1656, -0.1335]]],\n",
              "       device='cuda:0'), tensor([[[ 0.1006,  0.3494, -0.3405,  ..., -0.1035,  0.1020, -0.1610],\n",
              "         [ 0.0086,  0.2367, -0.2523,  ..., -0.0742,  0.0444, -0.0379],\n",
              "         [-0.0200,  0.2143, -0.2233,  ..., -0.0649,  0.0078, -0.0408],\n",
              "         ...,\n",
              "         [ 0.0475,  0.2390, -0.2198,  ..., -0.0608,  0.0456,  0.0032],\n",
              "         [ 0.0475,  0.2390, -0.2198,  ..., -0.0608,  0.0456,  0.0032],\n",
              "         [ 0.0475,  0.2390, -0.2198,  ..., -0.0608,  0.0456,  0.0032]],\n",
              "\n",
              "        [[-0.5517,  0.5926,  0.2953,  ...,  0.9635,  0.1289, -0.6083],\n",
              "         [-0.5527,  0.5931,  0.2939,  ...,  0.9727,  0.1282, -0.6118],\n",
              "         [-0.5528,  0.5935,  0.2941,  ...,  0.9722,  0.1282, -0.6121],\n",
              "         ...,\n",
              "         [-0.5526,  0.5934,  0.2938,  ...,  0.9721,  0.1283, -0.6117],\n",
              "         [-0.5526,  0.5934,  0.2938,  ...,  0.9721,  0.1283, -0.6117],\n",
              "         [-0.5526,  0.5934,  0.2938,  ...,  0.9721,  0.1283, -0.6117]],\n",
              "\n",
              "        [[ 0.6336,  0.5087, -0.7078,  ..., -0.3963,  0.2485,  0.3983],\n",
              "         [ 0.5507,  0.4283, -0.7342,  ..., -0.5897,  0.2251,  0.3802],\n",
              "         [ 0.5928,  0.4943, -0.7029,  ..., -0.4877,  0.2940,  0.4048],\n",
              "         ...,\n",
              "         [ 0.5790,  0.4764, -0.7402,  ..., -0.6575,  0.1939,  0.4734],\n",
              "         [ 0.5790,  0.4764, -0.7402,  ..., -0.6575,  0.1939,  0.4734],\n",
              "         [ 0.5790,  0.4764, -0.7402,  ..., -0.6575,  0.1939,  0.4734]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.0674,  0.3113, -0.3230,  ..., -0.0948,  0.1294, -0.1623],\n",
              "         [ 0.0068,  0.2049, -0.2467,  ..., -0.0620,  0.0572, -0.0217],\n",
              "         [-0.0218,  0.2258, -0.2277,  ..., -0.0576,  0.0545, -0.0382],\n",
              "         ...,\n",
              "         [ 0.0298,  0.2048, -0.2121,  ..., -0.0692,  0.0687, -0.0168],\n",
              "         [ 0.0298,  0.2048, -0.2121,  ..., -0.0692,  0.0687, -0.0168],\n",
              "         [ 0.0298,  0.2048, -0.2121,  ..., -0.0692,  0.0687, -0.0168]],\n",
              "\n",
              "        [[ 0.0668,  0.3131, -0.2813,  ..., -0.0965,  0.1471, -0.1394],\n",
              "         [-0.0370,  0.2298, -0.2030,  ..., -0.0348,  0.0633, -0.0675],\n",
              "         [-0.0171,  0.1982, -0.1739,  ..., -0.0328,  0.0537, -0.0359],\n",
              "         ...,\n",
              "         [ 0.0290,  0.2274, -0.1913,  ..., -0.0324,  0.1004, -0.0074],\n",
              "         [ 0.0290,  0.2274, -0.1913,  ..., -0.0324,  0.1004, -0.0074],\n",
              "         [ 0.0290,  0.2274, -0.1913,  ..., -0.0324,  0.1004, -0.0074]],\n",
              "\n",
              "        [[-0.5362,  0.6007,  0.2820,  ...,  0.9007,  0.1017, -0.5670],\n",
              "         [-0.5397,  0.6024,  0.2812,  ...,  0.9124,  0.1010, -0.5712],\n",
              "         [-0.5395,  0.6026,  0.2815,  ...,  0.9111,  0.1013, -0.5712],\n",
              "         ...,\n",
              "         [-0.5382,  0.6024,  0.2808,  ...,  0.9117,  0.1015, -0.5716],\n",
              "         [-0.5382,  0.6024,  0.2808,  ...,  0.9117,  0.1015, -0.5716],\n",
              "         [-0.5382,  0.6024,  0.2808,  ...,  0.9117,  0.1015, -0.5716]]],\n",
              "       device='cuda:0')), attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avaliação do modelo"
      ],
      "metadata": {
        "id": "bGgP4Jl7LTzh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "od0wcXeflyXD"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "-UKHK_wUlzi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "765cae8d-6521-4ad6-d702-6c67b53cc5be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12,  0,  0],\n",
              "       [ 0, 13,  0],\n",
              "       [ 1,  0, 20]])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "metrics.confusion_matrix(ytrue,ypred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "u4cSy9ill0n3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46899641-7f29-40eb-f0de-7699e02d565d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96        12\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      0.95      0.98        21\n",
            "\n",
            "    accuracy                           0.98        46\n",
            "   macro avg       0.97      0.98      0.98        46\n",
            "weighted avg       0.98      0.98      0.98        46\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(metrics.classification_report(ytrue,ypred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construção do bot no telegram"
      ],
      "metadata": {
        "id": "rgny1XkRLiIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install joblib\n",
        "!pip install python-telegram-bot torch transformers joblib"
      ],
      "metadata": {
        "id": "FNWwJTnELo14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f02dcea9-eacf-4683-d785-89705f56325a"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: python-telegram-bot in /usr/local/lib/python3.10/dist-packages (21.7)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: httpx~=0.27 in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot) (0.27.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx~=0.27->python-telegram-bot) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx~=0.27->python-telegram-bot) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx~=0.27->python-telegram-bot) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx~=0.27->python-telegram-bot) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx~=0.27->python-telegram-bot) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx~=0.27->python-telegram-bot) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx~=0.27->python-telegram-bot) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-telegram-bot\n",
        "\n",
        "from telegram import Update\n",
        "from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes\n",
        "import torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW6BGCh0NFYj",
        "outputId": "bc6446be-986c-441d-e3c9-8bf69da22ba6"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-telegram-bot in /usr/local/lib/python3.10/dist-packages (21.7)\n",
            "Requirement already satisfied: httpx~=0.27 in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot) (0.27.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx~=0.27->python-telegram-bot) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx~=0.27->python-telegram-bot) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx~=0.27->python-telegram-bot) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx~=0.27->python-telegram-bot) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx~=0.27->python-telegram-bot) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx~=0.27->python-telegram-bot) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx~=0.27->python-telegram-bot) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#salvar o modelo\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model_save_path = '/content/drive/My Drive/classificadorTextos.pth'\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "tokenizer_save_path = '/content/drive/My Drive/tokenizador'\n",
        "tokenizer.save_pretrained(tokenizer_save_path)"
      ],
      "metadata": {
        "id": "3fUtSYGbdg3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b34de5fd-8f80-4e73-9c94-f11ff0350adc"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/My Drive/tokenizador/tokenizer_config.json',\n",
              " '/content/drive/My Drive/tokenizador/special_tokens_map.json',\n",
              " '/content/drive/My Drive/tokenizador/vocab.json',\n",
              " '/content/drive/My Drive/tokenizador/merges.txt',\n",
              " '/content/drive/My Drive/tokenizador/added_tokens.json',\n",
              " '/content/drive/My Drive/tokenizador/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mapear_classe(numero_classe):\n",
        "    mapeamento = {\n",
        "        0: \"Negativo\",\n",
        "        1: \"Neutro\",\n",
        "        2: \"Positivo\"\n",
        "    }\n",
        "    return mapeamento.get(numero_classe, \"Classe Desconhecida\")"
      ],
      "metadata": {
        "id": "Eo1ivJn5PD6k"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classificar_texto(texto):\n",
        "    model.eval()\n",
        "    inputs = tokenizer(texto, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predicao = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "    return predicao.item()"
      ],
      "metadata": {
        "id": "LtYkQu06YOen"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
        "    await update.message.reply_text('Bot de Classificação de Textos 📊')\n",
        "\n",
        "async def classify_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
        "    try:\n",
        "        texto = update.message.text\n",
        "        classe_numerica = classificar_texto(texto)\n",
        "        classe_textual = mapear_classe(classe_numerica)\n",
        "        await update.message.reply_text(f\"Classificação: {classe_textual}\")\n",
        "    except Exception as e:\n",
        "        await update.message.reply_text(f\"Erro na classificação: {str(e)}\")\n",
        "\n",
        "async def start_bot():\n",
        "    application = Application.builder().token(\"8168617642:AAH5bTyVtbOc4yizIktIMaTjGNBjpjoNk3A\").build()\n",
        "\n",
        "    application.add_handler(CommandHandler(\"start\", start))\n",
        "    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, classify_message))\n",
        "\n",
        "    await application.run_polling()\n",
        "\n",
        "def iniciar_bot():\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "\n",
        "    import asyncio\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(start_bot())\n",
        "\n",
        "iniciar_bot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "QUkBiEhuKzdK",
        "outputId": "b5457199-4a51-4b7b-e100-089cc1038726"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Cannot close a running event loop",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-ec9f67dd6063>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_bot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0miniciar_bot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-103-ec9f67dd6063>\u001b[0m in \u001b[0;36miniciar_bot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_bot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0miniciar_bot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 raise RuntimeError(\n\u001b[1;32m     97\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-103-ec9f67dd6063>\u001b[0m in \u001b[0;36mstart_bot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mapplication\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMessageHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEXT\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMMAND\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassify_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mawait\u001b[0m \u001b[0mapplication\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_polling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0miniciar_bot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/telegram/ext/_application.py\u001b[0m in \u001b[0;36mrun_polling\u001b[0;34m(self, poll_interval, timeout, bootstrap_retries, read_timeout, write_timeout, connect_timeout, pool_timeout, allowed_updates, drop_pending_updates, close_loop, stop_signals)\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m         return self.__run(\n\u001b[0m\u001b[1;32m    866\u001b[0m             updater_coroutine=self.updater.start_polling(\n\u001b[1;32m    867\u001b[0m                 \u001b[0mpoll_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoll_interval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/telegram/ext/_application.py\u001b[0m in \u001b[0;36m__run\u001b[0;34m(self, updater_coroutine, stop_signals, close_loop)\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mclose_loop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m                     \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     def create_task(\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/unix_events.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finalizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_signal_handlers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/selector_events.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot close a running event loop\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Cannot close a running event loop"
          ]
        }
      ]
    }
  ]
}